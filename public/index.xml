<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TwentyFourSecs</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>TwentyFourSecs</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2020 Steven Golovkine. All Rights Reserved</copyright><lastBuildDate>Mon, 30 Dec 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/pic.jpg</url>
      <title>TwentyFourSecs</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Set up Julia</title>
      <link>/post/set-up-julia/</link>
      <pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate>
      <guid>/post/set-up-julia/</guid>
      <description>&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://julialang.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Julia&lt;/a&gt;
 can be installed on MacOS using Homebrew.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew cask install julia
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;jupyter-kernel&#34;&gt;Jupyter kernel&lt;/h2&gt;
&lt;p&gt;The installation of the Julia kernel for Jupyter is straightforward following this 
&lt;a href=&#34;https://github.com/JuliaLang/IJulia.jl/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;On MacOS, from a Terminal, run &lt;code&gt;julia&lt;/code&gt; to launch a Julia session. Then, run the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;using Pkg
Pkg.add(&amp;quot;IJulia&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Pretrained Models for Computer Vision</title>
      <link>/post/introduction-to-pretrained-models-for-computer-vision/</link>
      <pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/introduction-to-pretrained-models-for-computer-vision/</guid>
      <description>&lt;h1 id=&#34;introduction-to-pretrained-models-for-computer-vision&#34;&gt;Introduction to Pretrained Models for Computer Vision&lt;/h1&gt;
&lt;p&gt;This notebook is based on the Deep Learning course from the Master Datascience Paris Saclay. Materials of the course can be found 
&lt;a href=&#34;https://github.com/m2dsupsdlclass/lectures-labs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;It aims to get some hands-on experience with pre-trained Keras models are reasonably close to the state-of-the-art of some computer vision tasks. The models are pre-trained on large publicly available labeled images datasets such as 
&lt;a href=&#34;http://www.image-net.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ImageNet&lt;/a&gt;
 and 
&lt;a href=&#34;http://cocodataset.org/#home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;COCO&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;This notebook will highlights two specific tasks (or at least try):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Image Classification&lt;/strong&gt;: Predict only one class label per-image (assuming a single centered object or image class).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Object detection and instance segmentation&lt;/strong&gt;: Detect and localise all occurrences of objects of a predefined list of classes of interest in a given image.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Display figure in the notebook
%matplotlib inline
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Load packages
import cv2
import matplotlib.pyplot as plt
import numpy as np
import os
import zipfile

from keras import backend
from keras.applications import inception_resnet_v2, mobilenet, resnet50

from skimage.io import imread
from skimage.transform import resize

from time import time
from urllib.request import urlretrieve
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;working-with-images-data&#34;&gt;Working with images data&lt;/h2&gt;
&lt;p&gt;For the beginning, we will see how to work with images data, how they are represented in memory, how to load it, how to modify it, &lt;em&gt;ect.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s use the library 
&lt;a href=&#34;https://scikit-image.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;scikit-image&lt;/code&gt;&lt;/a&gt;
 to load the content of a JPEG file into a numpy array.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pic = imread(&#39;laptop.jpeg&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;The type of the variable is: &amp;lt;class &#39;imageio.core.util.Array&#39;&amp;gt; (which is a particular class of np.ndarray).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An image is described by three parameters: its height; its weight; its color channels (RGB). Each of them corresponds to a dimension of the array.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;The shape of the picture is (450, 800, 3).
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For efficiency reasons, the pixel intensities of each channel are stored as &lt;strong&gt;8-bit unsigned integer&lt;/strong&gt; taking values in the &lt;strong&gt;$[0, 255]$ range&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;The type of the elements in the array is uint8, the minimum value of the pixels is 0 and the maximum value is 255.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Look at the picture
fig = plt.imshow(pic)
fig.axes.get_xaxis().set_visible(False)
fig.axes.get_yaxis().set_visible(False)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_10_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;The size in bytes of a Numpy array can be computed by multiplying the number of elements by the size in byte of each element in the array. The size of one element depend of the data type.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Using the shape, the size of the image is 1.08MB, the computation is 450 (height) * 800 (weight) * 3 (channel) * 8 (# bits to represents one element) / 8 (# bits in one byte).
We can check this results using the function `nbytes`: 1.08MB.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indexing on the last dimension makes it possible to extract the 2D content of a specific color channel. Consider the following example for the red channel.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pic_red = pic[:, :, 0]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = plt.imshow(pic_red, cmap=plt.cm.Reds_r)
fig.axes.get_xaxis().set_visible(False)
fig.axes.get_yaxis().set_visible(False)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_15_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Now, we consider the grey-level version of the image with shape &lt;code&gt;(height, weight)&lt;/code&gt;. To compute this version, we compute the mean of each pixel values across the channels.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pic_grey = pic.mean(axis=2)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = plt.imshow(pic_grey, cmap=plt.cm.Greys_r)
fig.axes.get_xaxis().set_visible(False)
fig.axes.get_yaxis().set_visible(False)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_18_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;uint8&lt;/code&gt; integer data type can not represent the grey pixels because they have floating points.  Anyway, Numpy represents it as &lt;code&gt;float64&lt;/code&gt; data type.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;The size of the grey picture is 2.88MB (which is higher than the color picture, it is due to the `float` data type.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The expected of range values for the new pixels is the same as before, &lt;strong&gt;$[0, 255]$&lt;/strong&gt; (0 for white pixels and 255 for black ones).&lt;/p&gt;
&lt;h3 id=&#34;resizing-images-handling-data-types-and-dynamic-ranges&#34;&gt;Resizing images, handling data types and dynamic ranges&lt;/h3&gt;
&lt;p&gt;When dealing with an heterogeneous collection of image of various sizes, it is often necessary to resize the image to the same size. More specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;for &lt;strong&gt;image classification&lt;/strong&gt;, most networks expect a specific &lt;strong&gt;fixed input size&lt;/strong&gt;;&lt;/li&gt;
&lt;li&gt;for &lt;strong&gt;object detection&lt;/strong&gt; and instance segmentation, networks have more flexibility but the images should have &lt;strong&gt;approximately the same size as the training set images&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Furthermore, &lt;strong&gt;large images can be much slower to process&lt;/strong&gt; than smaller images. This is due to the fact that the number of pixels varies quadratically with the height and width.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Resize the picture to have a 50*50 picture.
pic = imread(&#39;laptop.jpeg&#39;)
pic_lowres = resize(pic, output_shape=(50, 50), mode=&#39;reflect&#39;, anti_aliasing=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = plt.imshow(pic_lowres, interpolation=&#39;nearest&#39;)
fig.axes.get_xaxis().set_visible(False)
fig.axes.get_yaxis().set_visible(False)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_24_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;The values of the pixels of the low resolution image are computed by combining the values of the pixels in the high resolution image. The result is therefore represented as floating points.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;The type of the elements of the array is float64, and the size of the image is 0.06MB.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Careful&lt;/strong&gt;, by conventions, both &lt;code&gt;skimage.transform.imresize&lt;/code&gt; and &lt;code&gt;plt.imshow&lt;/code&gt; assume that floating point values range from $0.0$ to $1.0$ when using floating points as opposed to $0$ to $255$ when using 8-bit integers.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;So, the range of pixel values of the low resolution image is [0.0, 0.996].
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that Keras on the other hand might expect images encoded with values in the $[0.0, 255.0]$ range irrespectively of the data type of the array. To avoid the implicit conversion to the $[0.0, 1.0]$ range, we can use the &lt;code&gt;preserve_range=True&lt;/code&gt; option in the &lt;code&gt;resize&lt;/code&gt; function. But the &lt;em&gt;dtype&lt;/em&gt; will change to &lt;em&gt;float64&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pic_lowres_larran = resize(pic, output_shape=(50, 50), mode=&#39;reflect&#39;, anti_aliasing=True, preserve_range=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;And, the range of pixel values of the low resolution image with `preserve_range=True` is [0.0, 254.0].
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: The behavior of &lt;code&gt;plt.imshow&lt;/code&gt; depends on both the &lt;em&gt;dtype&lt;/em&gt; and the dynamic range when displaying RGB images. In particular, it does not work on RGB images with &lt;em&gt;float64&lt;/em&gt; values in the $[0.0, 255.0]$ range.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = plt.imshow(pic_lowres_larran, interpolation=&#39;nearest&#39;)
fig.axes.get_xaxis().set_visible(False)
fig.axes.get_yaxis().set_visible(False)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_33_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;For correctly displaying an RGB array with floating point values in the $[0.0, 255.0]$ range, we can divide all the values by $255$ or change the &lt;em&gt;dtype&lt;/em&gt; to integers.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = plt.imshow(pic_lowres_larran / 255.0, interpolation=&#39;nearest&#39;)
fig.axes.get_xaxis().set_visible(False)
fig.axes.get_yaxis().set_visible(False)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_35_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = plt.imshow(pic_lowres_larran.astype(np.uint8), interpolation=&#39;nearest&#39;)
fig.axes.get_xaxis().set_visible(False)
fig.axes.get_yaxis().set_visible(False)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_36_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;optional-taking-snapshots-from-the-webcam&#34;&gt;(Optional) Taking snapshots from the webcam&lt;/h3&gt;
&lt;p&gt;We are going to use the 
&lt;a href=&#34;https://github.com/skvark/opencv-python&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Python API of OpenCV&lt;/a&gt;
 in order to take pictures.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Define a function to take a snapshot 
def take_snapshot(camera_id=0, fallback_filename=None):
    camera = cv2.VideoCapture(camera_id)
    try:
        # Take 10 consecutive snapshots to let the camera automatically
        # tune itself and hope that the contrast and lightning of the
        # last snapshot is good enough.
        for i in range(10):
            snapshot_ok, image = camera.read()
        if snapshot_ok:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            print(&#39;WARNING: Could not access the camera!&#39;)
            if fallback_filename:
                image = imread(fallback_filename)
    finally:
        camera.release()
    return image
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Test if the function take_snapshot is working.
pic = take_snapshot(camera_id=0, fallback_filename=&#39;laptop.jpeg&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;image-classification&#34;&gt;Image Classification&lt;/h2&gt;
&lt;p&gt;The Keras library includes several neural network models pretrained on the ImageNet classification dataset. A popular model that show a good tradeoff between computation speed, model size and accuracy is called &lt;em&gt;ResNet-50&lt;/em&gt; (
&lt;a href=&#34;https://arxiv.org/pdf/1512.03385.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
 for the article on Deep Residual Networks).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Get the ResNet-50 model
model = resnet50.ResNet50(weights=&#39;imagenet&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s check that Tensorflow backend used by Keras as the default backend expect the color channel on the last axis. If it had not been the case, it would have been possible to change the order of the axes with &lt;code&gt;pic = pic.transpose(2, 0, 1)&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;The color channel is on the channels_last.

The network has been trained on (224, 224) RGB images.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;None&lt;/code&gt; is used by Keras to mark dimensions with a dynamic number of elements. Here, &lt;code&gt;None&lt;/code&gt; is the &lt;em&gt;batch size&lt;/em&gt;, that is the number of images that can be processed at one. In the following, we will process only image at a time.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Load and resize the picture
pic = imread(&#39;laptop.jpeg&#39;)
pic_224 = resize(pic, (224, 224), preserve_range=True, mode=&#39;reflect&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;The shape of the picture is (224, 224, 3), and the dtype of its elements is float64.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the model use &lt;em&gt;float32&lt;/em&gt; dtype. So, we have to convert the picture into &lt;em&gt;float32&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pic_224 = pic_224.astype(np.float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = plt.imshow(pic_224 / 255, interpolation=&#39;nearest&#39;)
fig.axes.get_xaxis().set_visible(False)
fig.axes.get_yaxis().set_visible(False)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_50_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Note that the image has been deformed by the resizing. In practice, this should not degrade the performance of the network too much. There are two alternatives solutions to that problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;resizing the image so that the smallest side is set to 224;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;extracting a square centered crop of size $(224, 224)$ from the resulting image.&lt;/p&gt;
&lt;p&gt;The shape of the picture is (224, 224, 3), whereas the input shape of the model should be (None, 224, 224, 3). So we have to expand the dimension of the picture.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;pic_224_batch = pic_224[None, ...] # or np.expand_dims(pic_224, axis=0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;pic_224_batch&lt;/code&gt; is now compatible with the input shape of the neural network, so let&amp;rsquo;s make a prediction.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
X = resnet50.preprocess_input(pic_224_batch.copy())
pred = model.predict(X)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;CPU times: user 1.79 s, sys: 52 ms, total: 1.84 s
Wall time: 1.49 s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we make a copy each time as the function &lt;code&gt;preprocess_input&lt;/code&gt; can modify the image inplace to reuse memory when preprocessing large datasets.&lt;/p&gt;
&lt;p&gt;The output predictions are a 2D array with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One row per image in the batch;&lt;/li&gt;
&lt;li&gt;One column per target class in the ImageNet LSVRC dataset ($1000$ possible classes) with the probabilities that a given image belongs to a particular class. Obviously, the sum of the columns for each row is equal to $1$.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;decoding-the-predicition-probabilities&#34;&gt;Decoding the predicition probabilities&lt;/h3&gt;
&lt;p&gt;Reading the raw probabilities for the $1000$ possible ImageNet classes is tedious. Fortunately, Keras comes with an helper function to extract the highest rated classes according to the model and display both class names and the wordnet synset identifiers.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(&#39;Predicted image labels:&#39;)
for class_id, class_name, confidence in resnet50.decode_predictions(pred, top=5)[0]:
    print(f&amp;quot;\t* {class_name} (synset: {class_id}): {confidence}&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Predicted image labels:
    * notebook (synset: n03832673): 0.3599511384963989
    * laptop (synset: n03642806): 0.25687211751937866
    * desk (synset: n03179701): 0.15139059722423553
    * mouse (synset: n03793489): 0.11147501319646835
    * desktop_computer (synset: n03180011): 0.051331911236047745
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check on the ImageNet 
&lt;a href=&#34;https://www.image-net.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;
 to better understand the use of the terms &lt;em&gt;notebook&lt;/em&gt; in the training set. Note that the network is not too confident about the class of the main object in that image. If we were to merge the &lt;em&gt;notebook&lt;/em&gt; and the &lt;em&gt;laptop&lt;/em&gt; classes, the prediction will be good.&lt;/p&gt;
&lt;p&gt;Furthermore, the network also considers secondary objects (desk, mouse, &amp;hellip;) but the model as been trained as an image (multiclass) classification model with a single expected class per image rather than a multi-label classification model such as an object detection model with several positive labels per image.&lt;/p&gt;
&lt;p&gt;We have to keep that in mind when trying to make use of the predictions of such a model for a practical application. This is a fundamental limitation of the label structure of the training set.&lt;/p&gt;
&lt;h3 id=&#34;a-note-on-preprocessing&#34;&gt;A note on preprocessing&lt;/h3&gt;
&lt;p&gt;All Keras pretrained vision models expect images with &lt;code&gt;float32&lt;/code&gt; dtype and values in the $[0, 255]$ range. When training neural network, it often works better to have values closer to zero.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A typical preprocessing is to center each of the channel and normalize its variance.&lt;/li&gt;
&lt;li&gt;Another one is to measure the &lt;code&gt;min&lt;/code&gt; and the &lt;code&gt;max&lt;/code&gt; values and to shift and rescale to the $(-1, 1)$ range.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The exact kind of preprocessing is not very important, but it&amp;rsquo;s very important to &lt;strong&gt;always reuse the preprocessing function that was used when training the model&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Now, we are going to use different model, &lt;code&gt;ResNet50&lt;/code&gt;, &lt;code&gt;MobileNet&lt;/code&gt; and &lt;code&gt;InceptionResNetV2&lt;/code&gt;, to classify the images from Wikipedia. We can then compare the models in both time and prediction accuracy.&lt;/p&gt;
&lt;p&gt;We start be defining some function to predict the object in the images.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def classify_resnet50(model, fallback_filename=None):
    &amp;quot;&amp;quot;&amp;quot;
    Function that takes a snapshot of the webcam and display it
    along with the decoded prediction of the model and their
    confidence level.
    &amp;quot;&amp;quot;&amp;quot;
    # Take a snapshot
    pic = take_snapshot(camera_id=0, fallback_filename=fallback_filename)
    
    # Preprocess the picture
    pic_224 = resize(pic, (224, 224), preserve_range=True, mode=&#39;reflect&#39;)
    pic_224_batch = pic_224[None, ...]
    
    # Do predictions
    pred = model.predict(resnet50.preprocess_input(pic_224_batch.copy()))
    
    # Show the pic
    fig = plt.imshow(pic / 255, interpolation=&#39;nearest&#39;)
    fig.axes.get_xaxis().set_visible(False)
    fig.axes.get_yaxis().set_visible(False)
    plt.show()
    
    # Print the decoded predictions
    print(&#39;Predicted image labels:&#39;)
    for class_id, class_name, confidence in resnet50.decode_predictions(pred, top=5)[0]:
        print(f&amp;quot;\t* {class_name} (synset: {class_id}): {confidence}&amp;quot;)
        
def classify_mobilenet(model, fallback_filename=None):
    &amp;quot;&amp;quot;&amp;quot;
    Function that takes a snapshot of the webcam and display it
    along with the decoded prediction of the model and their
    confidence level.
    &amp;quot;&amp;quot;&amp;quot;
    # Take a snapshot
    pic = take_snapshot(camera_id=0, fallback_filename=fallback_filename)
    
    # Preprocess the picture
    pic_224 = resize(pic, (224, 224), preserve_range=True, mode=&#39;reflect&#39;)
    pic_224_batch = pic_224[None, ...]
    
    # Do predictions
    pred = model.predict(mobilenet.preprocess_input(pic_224_batch.copy()))
    
    # Show the pic
    fig = plt.imshow(pic / 255, interpolation=&#39;nearest&#39;)
    fig.axes.get_xaxis().set_visible(False)
    fig.axes.get_yaxis().set_visible(False)
    plt.show()
    
    # Print the decoded predictions
    print(&#39;Predicted image labels:&#39;)
    for class_id, class_name, confidence in mobilenet.decode_predictions(pred, top=5)[0]:
        print(f&amp;quot;\t* {class_name} (synset: {class_id}): {confidence}&amp;quot;)
        
def classify_inception_resnet_v2(model, fallback_filename=None):
    &amp;quot;&amp;quot;&amp;quot;
    Function that takes a snapshot of the webcam and display it
    along with the decoded prediction of the model and their
    confidence level.
    &amp;quot;&amp;quot;&amp;quot;
    # Take a snapshot
    pic = take_snapshot(camera_id=0, fallback_filename=fallback_filename)
    
    # Preprocess the picture
    pic_299 = resize(pic, (299, 299), preserve_range=True, mode=&#39;reflect&#39;)
    pic_299_batch = pic_299[None, ...]
    
    # Do predictions
    pred = model.predict(inception_resnet_v2.preprocess_input(pic_299_batch.copy()))
    
    # Show the pic
    fig = plt.imshow(pic / 255, interpolation=&#39;nearest&#39;)
    fig.axes.get_xaxis().set_visible(False)
    fig.axes.get_yaxis().set_visible(False)
    plt.show()
    
    # Print the decoded predictions
    print(&#39;Predicted image labels:&#39;)
    for class_id, class_name, confidence in inception_resnet_v2.decode_predictions(pred, top=5)[0]:
        print(f&amp;quot;\t* {class_name} (synset: {class_id}): {confidence}&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%%bash
wget https://upload.wikimedia.org/wikipedia/commons/3/3f/JPEG_example_flower.jpg
wget https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Alcatel_one_touch_easy.jpg/450px-Alcatel_one_touch_easy.jpg
wget https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/President_Barack_Obama.jpg/480px-President_Barack_Obama.jpg
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will begin the models comparison using the model &lt;code&gt;ResNet50&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Get the ResNet50 model
model_resnet50 = resnet50.ResNet50(weights=&#39;imagenet&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
classify_resnet50(model, &#39;JPEG_example_flower.jpg&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_67_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Predicted image labels:
    * pot (synset: n03991062): 0.37311553955078125
    * hair_slide (synset: n03476684): 0.08061367273330688
    * strawberry (synset: n07745940): 0.06821887940168381
    * vase (synset: n04522168): 0.05385832488536835
    * ant (synset: n02219486): 0.044536933302879333
CPU times: user 740 ms, sys: 112 ms, total: 852 ms
Wall time: 326 ms
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
classify_resnet50(model, &#39;450px-Alcatel_one_touch_easy.jpg&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_68_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Predicted image labels:
    * cellular_telephone (synset: n02992529): 0.9453017711639404
    * radio (synset: n04041544): 0.022191418334841728
    * hand-held_computer (synset: n03485407): 0.02068745717406273
    * combination_lock (synset: n03075370): 0.0010540278162807226
    * pay-phone (synset: n03902125): 0.001006232458166778
CPU times: user 716 ms, sys: 48 ms, total: 764 ms
Wall time: 307 ms
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
classify_resnet50(model, &#39;480px-President_Barack_Obama.jpg&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_69_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Predicted image labels:
    * groom (synset: n10148035): 0.7057098746299744
    * suit (synset: n04350905): 0.2643233835697174
    * gown (synset: n03450230): 0.009134724736213684
    * Windsor_tie (synset: n04591157): 0.008021678775548935
    * Loafer (synset: n03680355): 0.007970282807946205
CPU times: user 736 ms, sys: 40 ms, total: 776 ms
Wall time: 310 ms
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Get the MobileNet model
model_mobilenet = mobilenet.MobileNet(weights=&#39;imagenet&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
classify_mobilenet(model_mobilenet, &#39;JPEG_example_flower.jpg&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_71_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Predicted image labels:
    * lemon (synset: n07749582): 0.3409530222415924
    * orange (synset: n07747607): 0.2852575182914734
    * sulphur_butterfly (synset: n02281406): 0.1666731983423233
    * strawberry (synset: n07745940): 0.09244516491889954
    * whistle (synset: n04579432): 0.01351318508386612
CPU times: user 1.72 s, sys: 52 ms, total: 1.77 s
Wall time: 1.56 s
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
classify_mobilenet(model_mobilenet, &#39;450px-Alcatel_one_touch_easy.jpg&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_72_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Predicted image labels:
    * cellular_telephone (synset: n02992529): 0.5218481421470642
    * hand-held_computer (synset: n03485407): 0.4698248505592346
    * radio (synset: n04041544): 0.004865806549787521
    * dial_telephone (synset: n03187595): 0.0011262071784585714
    * remote_control (synset: n04074963): 0.0005011822795495391
CPU times: user 420 ms, sys: 12 ms, total: 432 ms
Wall time: 204 ms
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
classify_mobilenet(model_mobilenet, &#39;480px-President_Barack_Obama.jpg&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_73_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Predicted image labels:
    * groom (synset: n10148035): 0.6955855488777161
    * Windsor_tie (synset: n04591157): 0.17594707012176514
    * suit (synset: n04350905): 0.09634945541620255
    * organ (synset: n03854065): 0.006460004951804876
    * theater_curtain (synset: n04418357): 0.006234230939298868
CPU times: user 412 ms, sys: 40 ms, total: 452 ms
Wall time: 225 ms
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let&amp;rsquo;s fit the &lt;code&gt;InceptionResNetV2&lt;/code&gt; model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Get the InceptionResNetV2 model
model_inception_resnet_v2 = inception_resnet_v2.InceptionResNetV2(weights=&#39;imagenet&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
classify_inception_resnet_v2(model_inception_resnet_v2, &#39;JPEG_example_flower.jpg&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_76_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Predicted image labels:
    * lemon (synset: n07749582): 0.659601628780365
    * orange (synset: n07747607): 0.10027674585580826
    * pot (synset: n03991062): 0.09215866029262543
    * strawberry (synset: n07745940): 0.012752575799822807
    * sulphur_butterfly (synset: n02281406): 0.010476206429302692
CPU times: user 7.52 s, sys: 120 ms, total: 7.64 s
Wall time: 6.52 s
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
classify_inception_resnet_v2(model_inception_resnet_v2, &#39;450px-Alcatel_one_touch_easy.jpg&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_77_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Predicted image labels:
    * cellular_telephone (synset: n02992529): 0.8715960383415222
    * hand-held_computer (synset: n03485407): 0.013546744361519814
    * radio (synset: n04041544): 0.004702822770923376
    * modem (synset: n03777754): 0.004240750335156918
    * combination_lock (synset: n03075370): 0.0029042132664471865
CPU times: user 1.59 s, sys: 92 ms, total: 1.68 s
Wall time: 574 ms
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%time
classify_inception_resnet_v2(model_inception_resnet_v2, &#39;480px-President_Barack_Obama.jpg&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_78_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Predicted image labels:
    * suit (synset: n04350905): 0.39843690395355225
    * groom (synset: n10148035): 0.3309420049190521
    * Windsor_tie (synset: n04591157): 0.06947924941778183
    * theater_curtain (synset: n04418357): 0.04553558677434921
    * bow_tie (synset: n02883205): 0.004989056382328272
CPU times: user 1.58 s, sys: 68 ms, total: 1.64 s
Wall time: 574 ms
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;instance-detection-and-segmentation-with-mask-rcnn&#34;&gt;Instance Detection and Segmentation with Mask-RCNN&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://arxiv.org/pdf/1703.06870.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mask-RCNN&lt;/a&gt;
 is a refinement of the 
&lt;a href=&#34;https://arxiv.org/pdf/1506.01497.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Faster-RCNN&lt;/a&gt;
 &lt;strong&gt;object detection&lt;/strong&gt; model to also add support for &lt;strong&gt;instance segmentation&lt;/strong&gt;. The following shows how to use a 
&lt;a href=&#34;https://github.com/matterport/Mask_RCNN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Keras based implementation&lt;/a&gt;
 provided by 
&lt;a href=&#34;https://matterport.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Matterport&lt;/a&gt;
 along with model parameters pretrained on the  
&lt;a href=&#34;http://cocodataset.org/#home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;COCO Object Detection dataset&lt;/a&gt;
.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Download the model and the COCO trained weights
URL = &amp;quot;https://github.com/ogrisel/Mask_RCNN/archive/master.zip&amp;quot;
FOLDER = &#39;maskrcnn&#39;
FILENAME = &#39;Mask_RCNN-master.zip&#39;
if not os.path.exists(FOLDER):
    if not os.path.exists(FILENAME):
        tic = time()
        print(f&#39;Downloading {URL} to {FILENAME} (can take a couple of minutes)...&#39;)
        urlretrieve(URL, FILENAME)
        print(f&#39;Done in {time() - tic}&#39;)
    print(f&#39;Extracting archive to {FOLDER}...&#39;)
    zipfile.ZipFile(FILENAME).extractall(&#39;.&#39;)
    os.rename(&#39;Mask_RCNN-master&#39;, FOLDER)

COCO_MODEL_FILE = &#39;mask_rcnn_coco.h5&#39;
if not os.path.exists(COCO_MODEL_FILE):
    from maskrcnn import utils
    print(&#39;Pretrained model can take several minutes to download.&#39;)
    utils.download_trained_weights(COCO_MODEL_FILE)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;create-model-and-load-training-weights&#34;&gt;Create Model and Load Training Weights&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from maskrcnn import config
from maskrcnn import model as modellib

class InferenceCocoConfig(config.Config):
    # Give the configuration a recognizable name
    NAME = &#39;inference_coco&#39;
    
    # Number of classes (including background)
    NUM_CLASSES = 1 + 80 # COCO has 80 classes.
    
    # Set batch size to 1 since we&#39;ll be running inference on
    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
    
    
config = InferenceCocoConfig()
model = modellib.MaskRCNN(mode=&#39;inference&#39;, model_dir=&#39;mask_rcnn/logs&#39;, config=config)

# Load weights trained on MS-COCO
COCO_MODEL_FILE = &#39;mask_rcnn_coco.h5&#39;
model.load_weights(COCO_MODEL_FILE, by_name=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;class-names&#34;&gt;Class Names&lt;/h3&gt;
&lt;p&gt;Index of the class in the list is its ID. For example, to get ID of the teddy bear class, use: &lt;code&gt;class_names.index(&#39;teddy bear&#39;)&lt;/code&gt;. &lt;code&gt;BG&lt;/code&gt; stands for background.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# COCO class names
class_names = [&#39;BG&#39;, &#39;person&#39;, &#39;bicycle&#39;, &#39;car&#39;, &#39;motorcycle&#39;, &#39;airplane&#39;,
               &#39;bus&#39;, &#39;train&#39;, &#39;truck&#39;, &#39;boat&#39;, &#39;traffic light&#39;,
               &#39;fire hydrant&#39;, &#39;stop sign&#39;, &#39;parking meter&#39;, &#39;bench&#39;, &#39;bird&#39;,
               &#39;cat&#39;, &#39;dog&#39;, &#39;horse&#39;, &#39;sheep&#39;, &#39;cow&#39;, &#39;elephant&#39;, &#39;bear&#39;,
               &#39;zebra&#39;, &#39;giraffe&#39;, &#39;backpack&#39;, &#39;umbrella&#39;, &#39;handbag&#39;, &#39;tie&#39;,
               &#39;suitcase&#39;, &#39;frisbee&#39;, &#39;skis&#39;, &#39;snowboard&#39;, &#39;sports ball&#39;,
               &#39;kite&#39;, &#39;baseball bat&#39;, &#39;baseball glove&#39;, &#39;skateboard&#39;,
               &#39;surfboard&#39;, &#39;tennis racket&#39;, &#39;bottle&#39;, &#39;wine glass&#39;, &#39;cup&#39;,
               &#39;fork&#39;, &#39;knife&#39;, &#39;spoon&#39;, &#39;bowl&#39;, &#39;banana&#39;, &#39;apple&#39;,
               &#39;sandwich&#39;, &#39;orange&#39;, &#39;broccoli&#39;, &#39;carrot&#39;, &#39;hot dog&#39;, &#39;pizza&#39;,
               &#39;donut&#39;, &#39;cake&#39;, &#39;chair&#39;, &#39;couch&#39;, &#39;potted plant&#39;, &#39;bed&#39;,
               &#39;dining table&#39;, &#39;toilet&#39;, &#39;tv&#39;, &#39;laptop&#39;, &#39;mouse&#39;, &#39;remote&#39;,
               &#39;keyboard&#39;, &#39;cell phone&#39;, &#39;microwave&#39;, &#39;oven&#39;, &#39;toaster&#39;,
               &#39;sink&#39;, &#39;refrigerator&#39;, &#39;book&#39;, &#39;clock&#39;, &#39;vase&#39;, &#39;scissors&#39;,
               &#39;teddy bear&#39;, &#39;hair drier&#39;, &#39;toothbrush&#39;]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;run-object-detection&#34;&gt;Run Object Detection&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s perform object segmentation on an image taken on the web.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%%bash
wget https://storage.needpix.com/rsynced_images/street-scene-2301158_1280.jpg
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Read the image
pic = imread(&#39;street-scene-2301158_1280.jpg&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = plt.imshow(pic, interpolation=&#39;nearest&#39;)
fig.axes.get_xaxis().set_visible(False)
fig.axes.get_yaxis().set_visible(False)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_88_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from maskrcnn import visualize

# Run detection
tic = time()
results = model.detect([pic], verbose=1)
toc = time()
print(f&#39;Image analyzed in {np.around(toc - tic, 2)} secondes.&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Processing 1 images
image                    shape: (960, 1280, 3)        min:    0.00000  max:  255.00000
molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  150.11562
image_metas              shape: (1, 89)               min:    0.00000  max: 1280.00000
Image analyzed in 13.57 secondes.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Visualize the results
r = results[0] # Take the results for the first image.
for class_id, score in zip(r[&#39;class_ids&#39;], r[&#39;scores&#39;]):
    print(f&#39;{class_names[class_id]}:\t{score}&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;car:	0.9879944324493408
car:	0.9879814982414246
car:	0.9828053116798401
car:	0.9798809289932251
car:	0.9787180423736572
car:	0.9613178968429565
car:	0.9486448168754578
car:	0.9470494389533997
motorcycle:	0.9209350943565369
motorcycle:	0.9195521473884583
car:	0.9188504815101624
car:	0.9100474119186401
car:	0.9096055626869202
car:	0.8942683339118958
car:	0.8911943435668945
person:	0.8910031914710999
person:	0.8883078098297119
bus:	0.8868105411529541
car:	0.8834719061851501
person:	0.8810924291610718
car:	0.8774976134300232
car:	0.870510995388031
bus:	0.8356407284736633
motorcycle:	0.8196616172790527
bus:	0.8100437521934509
person:	0.8088014721870422
person:	0.8027144074440002
person:	0.8002358675003052
car:	0.7951725721359253
car:	0.7892614006996155
person:	0.787919282913208
motorcycle:	0.7864757776260376
car:	0.7821618318557739
person:	0.771487832069397
person:	0.7644047141075134
bus:	0.7624491453170776
person:	0.7461680769920349
car:	0.7306007742881775
car:	0.7271723747253418
car:	0.7174354195594788
car:	0.7103606462478638
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Visualization on the picture
visualize.display_instances(pic, r[&#39;rois&#39;], r[&#39;masks&#39;], 
                            r[&#39;class_ids&#39;],
                            class_names, r[&#39;scores&#39;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_91_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Deep Learning with Keras</title>
      <link>/post/introduction-to-deep-learning-with-keras/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/introduction-to-deep-learning-with-keras/</guid>
      <description>&lt;p&gt;This post is based on the Deep Learning course from the Master Datascience Paris Saclay. Materials of the course can be found 
&lt;a href=&#34;https://github.com/m2dsupsdlclass/lectures-labs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;
. The complete code can be found on a Kaggle 
&lt;a href=&#34;https://www.kaggle.com/stevengolo/introduction-to-deep-learning-with-keras&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kernel&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Goal of the post&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Train a simple neural network (Multi-Layer Perceptron) with the high level framework &lt;code&gt;Keras&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Dataset used&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The MNIST dataset (
&lt;a href=&#34;https://www.kaggle.com/c/digit-recognizer/overview&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kaggle link&lt;/a&gt;
).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;output_6_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: An example of an image in the dataset.
&lt;/p&gt;
&lt;/center&gt;
&lt;h1 id=&#34;preprocessing&#34;&gt;Preprocessing&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;During this step, we will do some normalization on both the training and testing dataset.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Extract and convert the pixel as numpy array with dtype=&#39;float32&#39;
train = np.asarray(digits_train.iloc[:, 1:], dtype=&#39;float32&#39;)
test = np.asarray(digits_test, dtype=&#39;float32&#39;)

train_target = np.asarray(digits_train.loc[:, &#39;label&#39;], dtype=&#39;int32&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Scale the data
scaler = preprocessing.StandardScaler()
train_scale = scaler.fit_transform(train)
test_scale = scaler.transform(test)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_10_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: An example of a scaled image in the dataset.
&lt;/p&gt;
&lt;/center&gt;
&lt;h1 id=&#34;a-feed-forward-neural-network-with-keras&#34;&gt;A Feed Forward Neural Network with Keras&lt;/h1&gt;
&lt;h2 id=&#34;objectives&#34;&gt;Objectives&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Build and train a first feedforward network using Keras. Guide to 
&lt;a href=&#34;https://keras.io/getting-started/sequential-model-guide/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sequential model&lt;/a&gt;
 in Keras.&lt;/li&gt;
&lt;li&gt;Experiment with different optimizers, activations, size of layers or initializations.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-keras-works&#34;&gt;How Keras works?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;In order to build a neural network, we need to turn the target variable into a &amp;ldquo;one-hot-encoding&amp;rdquo; vector representation. There are multiple to do so. One may use the function &lt;code&gt;OneHotEncoder&lt;/code&gt; from &lt;code&gt;sklearn.preprocessing&lt;/code&gt;, but as we want to work with Keras, we should use the utility function provided by him.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Encoded the target vector as one-hot-encoding vector.
target = to_categorical(train_target)
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The high level API of Keras needs some objects to build a feed forward neural network:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A model by stacking layers with the right dimensions;&lt;/li&gt;
&lt;li&gt;A loss function with an optimizer;&lt;/li&gt;
&lt;li&gt;Some training data.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;rsquo;s build a first model with only one hidden layer with a &lt;code&gt;tanh&lt;/code&gt; activation function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Define some parameters
N = train.shape[1] # Length of one data
H = 100 # Dimension of the hidden layer
K = 10 # Dimension of the output layer (number of classes to predict)
lr = 0.1 # Learning rate for the loss function
epochs = 15 # Number of epochs for the NN
batch_size = 32 # Size of the batch

# Define the model
model = Sequential()
model.add(Dense(H, input_dim=N, activation=&#39;tanh&#39;))
model.add(Dense(K, activation=&#39;softmax&#39;))

# Print the model
model.summary()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;_________________________________________________________________
  Layer (type)                 Output Shape              Param #   
=================================================================
  dense_1 (Dense)              (None, 100)               78500     
_________________________________________________________________
  dense_2 (Dense)              (None, 10)                1010      
=================================================================
  Total params: 79,510
  Trainable params: 79,510
  Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Define the loss function with the SGD optimizer
model.compile(optimizer=optimizers.SGD(lr=lr),
             loss=&#39;categorical_crossentropy&#39;,
             metrics=[&#39;accuracy&#39;])

# Fit the model
history = model.fit(train_scale, target, epochs=epochs, batch_size=batch_size, verbose=0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_16_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Accuracy and loss of the model through the epochs using the SGD optimizer.
&lt;/p&gt;
&lt;/center&gt;
&lt;h2 id=&#34;influence-of-the-learning-rate&#34;&gt;Influence of the learning rate&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Let&amp;rsquo;s look at the influence of the learning rate on the training loss and accuracy. We consider a learning rate from 0.001 to 10.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;lrs = np.logspace(-3, 1, num=5)
history = dict()
for lr in lrs :
  model = Sequential()
  model.add(Dense(H, input_dim=N, activation=&#39;tanh&#39;))
  model.add(Dense(K, activation=&#39;softmax&#39;))
  model.compile(optimizer=optimizers.SGD(lr=lr), loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])
  history[lr] = model.fit(train_scale, target, epochs=epochs, batch_size=batch_size, verbose=0).history
  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_19_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Accuracy and loss of the model through the epochs for different learning rates.
&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;As we see on the graphs, the learning rate has an influence of the speed of convergence and even on the possible divergence. So, for this dataset, when the learning rate is 10, the model does not converge. However, for the learning rate equals to 0.001, 0.01 and 1, the model still converges but it is slower than for the learning rate of 0.1.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Let&amp;rsquo;s modify the 
&lt;a href=&#34;https://www.jstor.org/stable/2236626?seq=1#page_scan_tab_contents&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SGD&lt;/a&gt;
 optimizer to enable a Nesterov momentum of 0.9. The momentum is used to mitigate the small learning rate or slow training problem a little. However, here, it seems that is not working.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = Sequential()
model.add(Dense(H, input_dim=N, activation=&#39;tanh&#39;))
model.add(Dense(K, activation=&#39;softmax&#39;))
model.compile(optimizer=optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True),
             loss=&#39;categorical_crossentropy&#39;,
             metrics=[&#39;accuracy&#39;])
history = model.fit(train_scale, target, epochs=epochs, batch_size=batch_size, verbose=0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_22_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: Accuracy and loss of the model through the epochs using the Nesterov momentum.
&lt;/p&gt;
&lt;/center&gt;
&lt;h2 id=&#34;influence-of-the-optimizer&#34;&gt;Influence of the optimizer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Now, let&amp;rsquo;s try the 
&lt;a href=&#34;https://arxiv.org/abs/1412.6980&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adam&lt;/a&gt;
 optimizer.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = Sequential()
model.add(Dense(H, input_dim=N, activation=&#39;tanh&#39;))
model.add(Dense(K, activation=&#39;softmax&#39;))
model.compile(optimizer=optimizers.Adam(),
             loss=&#39;categorical_crossentropy&#39;,
             metrics=[&#39;accuracy&#39;])
history = model.fit(train_scale, target, epochs=epochs, batch_size=batch_size, verbose=0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_25_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 6: Accuracy and loss of the model through the epochs using the Adam optimizer.
&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;The Adam optimizer with default parameters performs quite well on this model. In fact, the results are comparable with the SGD optimizer with learning rate 0.1 whereas the default learning rate of the Adam optimizer is 0.001.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Let&amp;rsquo;s add another hidden layer to the model with the &lt;code&gt;relu&lt;/code&gt; activation function.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = Sequential()
model.add(Dense(H, input_dim=N, activation=&#39;relu&#39;))
model.add(Dense(H, activation=&#39;relu&#39;))
model.add(Dense(K, activation=&#39;softmax&#39;))
model.compile(optimizer=optimizers.Adam(),
             loss=&#39;categorical_crossentropy&#39;,
             metrics=[&#39;accuracy&#39;])
history = model.fit(train_scale, target, epochs=epochs, batch_size=batch_size, verbose=0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_28_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 7: Accuracy and loss of the model through the epochs with another hidden layers.
&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;When we add another hidden layer and change the activation function, the results with default parameters are in some sense less good than before. However, it does seem to be a problem to train the model with Adam default parameters.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Let&amp;rsquo;s try a last one optimizer, the 
&lt;a href=&#34;https://arxiv.org/abs/1212.5701&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Adadelta&lt;/a&gt;
 optimizer (no learning rate to set).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = Sequential()
model.add(Dense(H, input_dim=N, activation=&#39;tanh&#39;))
model.add(Dense(K, activation=&#39;softmax&#39;))
model.compile(optimizer=optimizers.Adadelta(),
             loss=&#39;categorical_crossentropy&#39;,
             metrics=[&#39;accuracy&#39;])
history = model.fit(train_scale, target, epochs=epochs, batch_size=batch_size, verbose=0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_31_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 8: Accuracy and loss of the model through the epochs using the Adadelta optimizer.
&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;The Adadelta seems to give very good results on this dataset. No learning rate are required for this optimizer, in fact, it adapts the learning rate over time.&lt;/p&gt;
&lt;h2 id=&#34;forward-pass-and-generalization&#34;&gt;Forward pass and generalization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Now, we are gonna use the last model we fit to make prediction on the test set.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;prediction = model.predict_classes(test)
&lt;/code&gt;&lt;/pre&gt;
&lt;center&gt;
&lt;p float=&#34;left&#34;&gt;
  &lt;img src=&#34;output_35_0.png&#34; width=&#34;200&#34; /&gt;
  &lt;img src=&#34;output_35_1.png&#34; width=&#34;200&#34; /&gt; 
&lt;/p&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 9: Examples of prediction.
&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;Submitting this very simple model, with only one hidden layer, leads to a 88% accuracy.&lt;/p&gt;
&lt;h2 id=&#34;impact-of-initialization&#34;&gt;Impact of initialization&lt;/h2&gt;
&lt;p&gt;Let us now study the impact of initialization when training a deep feed forward network. By default, Keras dense layers use the &lt;em&gt;Glorot Uniform&lt;/em&gt; initialization strategy to initialize the weigth matrices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each weight coefficient is randomly sampled from $[-scale, scale]$;&lt;/li&gt;
&lt;li&gt;scale is proportional to $1 / \sqrt{n_{in} + n_{out}}$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This strategy is known to work well to initialize deep neural networks with &lt;code&gt;tanh&lt;/code&gt; or &lt;code&gt;relu&lt;/code&gt; activation functions and then trained with standard SGD. To assess the impact of initialization, let us plug an alternative init scheme into a two hidden layers networks with &lt;code&gt;tanh&lt;/code&gt; activation functions. For the sake of the example, let&amp;rsquo;s use normal distributed weights with a manually adjustable scale (standard deviation) and see the impact of the scale value.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Define a random normal initializers.
normal_init = initializers.RandomNormal(stddev=0.01)

model = Sequential()
model.add(Dense(H, input_dim=N, activation=&#39;tanh&#39;, kernel_initializer=normal_init))
model.add(Dense(K, activation=&#39;tanh&#39;, kernel_initializer=normal_init))
model.add(Dense(K, activation=&#39;softmax&#39;, kernel_initializer=normal_init))

model.compile(optimizer=optimizers.SGD(lr=lr),
             loss=&#39;categorical_crossentropy&#39;,
             metrics=[&#39;accuracy&#39;])

model.summary()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_22 (Dense)             (None, 100)               78500     
_________________________________________________________________
dense_23 (Dense)             (None, 10)                1010      
_________________________________________________________________
dense_24 (Dense)             (None, 10)                110       
=================================================================
Total params: 79,620
Trainable params: 79,620
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s have a look at the parameters of the first layer after initialization but before any training has happened.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;w = model.layers[0].weights[0].eval(keras.backend.get_session())
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Initialization weights: 
     - mean = 0.0
     - standard deviation = 0.009999999776482582
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;b = model.layers[0].weights[1].eval(keras.backend.get_session())
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Initialization bias: 
     - mean = 0.0
     - standard deviation = 0.0
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;history = model.fit(train_scale, target, epochs=epochs, batch_size=batch_size, verbose=0)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;output_46_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 10: Accuracy and loss of the model through the epochs with a Normal initialization for the weights.
&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;We see that with this initialization the SGD algorithm can not train the network in 15 epochs.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Define different initializations
init_list = [
    (&#39;Glorot Uniform Init&#39;, &#39;glorot_uniform&#39;),
    (&#39;Small Scale Init&#39;, initializers.RandomNormal(stddev=1e-3)),
    (&#39;Large Scale Init&#39;, initializers.RandomNormal(stddev=1)),
    (&#39;Zero Weights Init&#39;, &#39;zero&#39;)
]

optimizer_list = [
    (&#39;SGD&#39;, optimizers.SGD(lr=lr)),
    (&#39;Adam&#39;, optimizers.Adam()),
    (&#39;SGD + Nesterov momentum&#39;, optimizers.SGD(lr=lr, momentum=0.9, nesterov=True))
]

history = dict()
for optimizer_name, optimizer in optimizer_list:
    for init_name, init in init_list:
        model = Sequential()
        model.add(Dense(H, input_dim=N, activation=&#39;tanh&#39;, kernel_initializer=init))
        model.add(Dense(K, activation=&#39;tanh&#39;, kernel_initializer=init))
        model.add(Dense(K, activation=&#39;softmax&#39;, kernel_initializer=init))
        model.compile(optimizer=optimizer, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])
        history[(optimizer_name, init_name)] = model.fit(train_scale, target, epochs=epochs, batch_size=batch_size, verbose=0)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;initialization-with-zero-weights&#34;&gt;Initialization with zero weights&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;output_49_3.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;output_49_7.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;output_49_11.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 11: Accuracy and loss of the models through the epochs with zero weights initialization.
&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;If the network is initialized to zero weights, the activations of the hidden layers are always set to zero, whatever the value of the inputs. The gradient is always zero for all training samples and no learning can happen with any gradient-based optimizer (SGD, Adam, &amp;hellip;): the loss stays constant.&lt;/p&gt;
&lt;p&gt;A network with null weigths has null gradients but this is not a local minimum (nor a local maximum): it is a saddle point at the center of a neighborhood with very low gradients.&lt;/p&gt;
&lt;h3 id=&#34;initialization-with-small-scale&#34;&gt;Initialization with small scale&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;output_49_1.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;output_49_5.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;output_49_9.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 12: Accuracy and loss of the model through the epochs with small scale initialization.
&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;Therefore when the scale of a random initializations of the weights is too small, SGD has a hard time evading that area of low gradients. Adding momentum can help but especially for deep networks it can take many epochs to evade the area.&lt;/p&gt;
&lt;h3 id=&#34;initialization-with-large-scale&#34;&gt;Initialization with large scale&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;output_49_2.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;output_49_6.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;output_49_10.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 13: Accuracy and loss of the model through the epochs with large scale initialization.
&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;Initializating the weights with large random values will make the ouput distribution (softmax) very peaky: the network is very &amp;ldquo;confident&amp;rdquo; of its predictions even if they are completely random. This leads to a very high initial loss value.&lt;/p&gt;
&lt;p&gt;The softmax function does not saturate (bad classification always have a non-zero gradient). However, the intermediate tanh layers can saturate, therefore squashing the gradient of the loss with respect to the parameters of the first &amp;ldquo;Dense&amp;rdquo; layer and making the network train much slower.&lt;/p&gt;
&lt;h3 id=&#34;initialization-with-glorot-uniform&#34;&gt;Initialization with Glorot Uniform&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;output_49_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;output_49_4.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;output_49_8.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;center&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 13: Accuracy and loss of the model through the epochs with Glorot Uniform initialization.
&lt;/p&gt;
&lt;/center&gt;
&lt;p&gt;The Glorot uniform init uses a scale that depends on the dimensions of the weight matrix so has to preserve the average norm of activations and flowing gradients so as to make learning possible. Keras provides alternatives that can be better in some cases. Look at this 
&lt;a href=&#34;http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt;
 for more information.&lt;/p&gt;
&lt;p&gt;Adam tends to be more robust when it comes to bad initialization thanks to its per-weight learning rate adjustments but still benefits from a good initialization.&lt;/p&gt;
&lt;p&gt;Things to remember if your network fails to learn at all (the loss stays at its inital value):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ensure that the weights are properly initialized;&lt;/li&gt;
&lt;li&gt;inspect the per-layer gradient norms to help identify the bad layer;&lt;/li&gt;
&lt;li&gt;use Adam instead of SGD as your default go to initializer.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>knitr</title>
      <link>/post/knitr/</link>
      <pubDate>Thu, 25 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/post/knitr/</guid>
      <description>&lt;p&gt;The package &lt;code&gt;knitr&lt;/code&gt; has been created by Yihui Xie. It is disponible on the 
&lt;a href=&#34;https://cran.r-project.org/web/packages/knitr/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN&lt;/a&gt;
. Check out the official 
&lt;a href=&#34;https://yihui.name/knitr/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;
 for more information. It is designed to build and generate nice report in &lt;strong&gt;R&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;questions&#34;&gt;Questions&lt;/h2&gt;
&lt;h3 id=&#34;how-to-render-latex-formula-in-ggplot-graphs-in-a-report-in-html&#34;&gt;How to render Latex formula in ggplot graphs in a report in html?&lt;/h3&gt;
&lt;p&gt;For a report in pdf, it is quite easy to render Latex formula in a ggplot graph. Just set the &lt;code&gt;dev&lt;/code&gt; variable to &lt;code&gt;&#39;tikz&#39;&lt;/code&gt; in a &lt;strong&gt;R&lt;/strong&gt; chunk. However, this method produces a pdf of the picture, and some browsers seem to have some trouble to show pdf files. So, the idea is to convert the pdf of the picture into a png file. For that, the &lt;strong&gt;R&lt;/strong&gt; chunk accept the option &lt;code&gt;fig.process&lt;/code&gt; and we will modify it to solve our problem.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34;&gt;fig.process &amp;lt;- function(x) {
    x &amp;lt;- paste0(&#39;./&#39;, x)
    
    if(stringr::str_detect(x, &#39;pdf&#39;)){
      y &amp;lt;- stringr::str_replace(x, &#39;pdf&#39;, &#39;png&#39;)
      png::writePNG(pdftools::pdf_render_page(x), target = y, dpi = 300)
      return(y)
    } else {
      return(x)
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function &lt;code&gt;fig.process&lt;/code&gt; takes a string as input (the path of the picture). If the picture is in pdf, it will convert it into png, otherwise, it will do nothing. And finally, the browser will render the picture correctly.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DonnÃ©es fonctionnelles avec erreur hÃ©tÃ©roscÃ©dastique</title>
      <link>/talk/sfds-2019/</link>
      <pubDate>Mon, 03 Jun 2019 11:00:00 +0000</pubDate>
      <guid>/talk/sfds-2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Clustering multivariate functional data defined on random domains: an application to vehicle trajectories analysis</title>
      <link>/talk/mascot_num_2019/</link>
      <pubDate>Mon, 18 Mar 2019 15:00:00 +0000</pubDate>
      <guid>/talk/mascot_num_2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Lower Back Pain</title>
      <link>/project/lower-back-pain/</link>
      <pubDate>Sat, 05 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/project/lower-back-pain/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#context&#34;&gt;Context&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#question&#34;&gt;Question&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exploration-of-the-data&#34;&gt;Exploration of the data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subset-features-selection&#34;&gt;Subset features selection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#model-construction&#34;&gt;Model construction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;This dataset is provided by sammy123 on &lt;a href=&#34;https://www.kaggle.com/sammy123/lower-back-pain-symptoms-dataset&#34;&gt;Kaggle&lt;/a&gt;. My study and the complete code are on a Kaggle &lt;a href=&#34;https://www.kaggle.com/stevengolo/lower-back-pain-syndrom&#34;&gt;kernel&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;context&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Context&lt;/h1&gt;
&lt;p&gt;Lower back pain can be caused by a variety of problems with any parts of the complex, interconnected network of spinal muscles, nerves, bones, discs or tendons in the lumbar spines. Typical sources of low back pain include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The large nerve roots in the low back that go to the legs may be irritated.&lt;/li&gt;
&lt;li&gt;The smaller nerves that supply the low back may be irritated.&lt;/li&gt;
&lt;li&gt;The large paired lower back muscles (erector spinae) may be strained.&lt;/li&gt;
&lt;li&gt;The bones, ligaments or joints may be damaged.&lt;/li&gt;
&lt;li&gt;An intervertebral disc may be degenerating.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An irritation or problem with any of these structures can cause lower back pain and/or pain that radiates or is referred to other parts of the body. Many lower back problems can also cause back muscle spasms, which do not sound like much but can cause severe pain and disability.&lt;/p&gt;
&lt;p&gt;While lower back pain is extremely common, the symptoms and severity of lower back pain vary greatly. A simple lower back muscle strain might be excruciating enough to necessitate an emergency room visit, while a degenerating disc might cause only mild, intermittent discomfort.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;question&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Question&lt;/h1&gt;
&lt;p&gt;How identify an abnormal or normal person using collected physical spine details and data?&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Import the data
data = pd.read_csv(&amp;quot;Dataset_spine.csv&amp;quot;, decimal=&amp;#39;.&amp;#39;, sep=&amp;#39;,&amp;#39;, header=0)
data = data.drop(&amp;#39;Unnamed: 13&amp;#39;, 1)
data.columns = [&amp;#39;pelvic_incidence&amp;#39;, &amp;#39;pelvic_tilt&amp;#39;,
                &amp;#39;lumbar_lordosis_angle&amp;#39;, &amp;#39;sacral_slope&amp;#39;,
                &amp;#39;pelvic_radius&amp;#39;, &amp;#39;degree_spondylolisthesis&amp;#39;,
                &amp;#39;pelvic_slope&amp;#39;, &amp;#39;direct_tilt&amp;#39;,
                &amp;#39;thoracic_slope&amp;#39;, &amp;#39;cervical_tilt&amp;#39;,
                &amp;#39;sacrum_angle&amp;#39;, &amp;#39;scoliosis_slope&amp;#39;,
                &amp;#39;class&amp;#39;]

data.head()&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;overflow-x:auto;&#34;&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
Pelvic Incidence
&lt;/th&gt;
&lt;th&gt;
Pelvic Tilt
&lt;/th&gt;
&lt;th&gt;
Lumbar Lordosis Angle
&lt;/th&gt;
&lt;th&gt;
Sacral Slope
&lt;/th&gt;
&lt;th&gt;
Pelvic Radius
&lt;/th&gt;
&lt;th&gt;
Degree Spondylolisthesis
&lt;/th&gt;
&lt;th&gt;
Pelvic Slope
&lt;/th&gt;
&lt;th&gt;
Direct Tilt
&lt;/th&gt;
&lt;th&gt;
Thoracic Slope
&lt;/th&gt;
&lt;th&gt;
Cervical Tilt
&lt;/th&gt;
&lt;th&gt;
Sacrum Angle
&lt;/th&gt;
&lt;th&gt;
Scoliosis Slope
&lt;/th&gt;
&lt;th&gt;
Class
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;
63.027818
&lt;/td&gt;
&lt;td&gt;
22.552586
&lt;/td&gt;
&lt;td&gt;
39.609117
&lt;/td&gt;
&lt;td&gt;
40.475232
&lt;/td&gt;
&lt;td&gt;
98.672917
&lt;/td&gt;
&lt;td&gt;
-0.254400
&lt;/td&gt;
&lt;td&gt;
0.744503
&lt;/td&gt;
&lt;td&gt;
12.5661
&lt;/td&gt;
&lt;td&gt;
14.5386
&lt;/td&gt;
&lt;td&gt;
15.30468
&lt;/td&gt;
&lt;td&gt;
-28.658501
&lt;/td&gt;
&lt;td&gt;
43.5123
&lt;/td&gt;
&lt;td&gt;
Abnormal
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
39.056951
&lt;/td&gt;
&lt;td&gt;
10.060991
&lt;/td&gt;
&lt;td&gt;
25.015378
&lt;/td&gt;
&lt;td&gt;
28.995960
&lt;/td&gt;
&lt;td&gt;
114.405425
&lt;/td&gt;
&lt;td&gt;
4.564259
&lt;/td&gt;
&lt;td&gt;
0.415186
&lt;/td&gt;
&lt;td&gt;
12.8874
&lt;/td&gt;
&lt;td&gt;
17.5323
&lt;/td&gt;
&lt;td&gt;
16.78486
&lt;/td&gt;
&lt;td&gt;
-25.530607
&lt;/td&gt;
&lt;td&gt;
16.1102
&lt;/td&gt;
&lt;td&gt;
Abnormal
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
68.832021
&lt;/td&gt;
&lt;td&gt;
22.218482
&lt;/td&gt;
&lt;td&gt;
50.092194
&lt;/td&gt;
&lt;td&gt;
46.613539
&lt;/td&gt;
&lt;td&gt;
105.985135
&lt;/td&gt;
&lt;td&gt;
-3.530317
&lt;/td&gt;
&lt;td&gt;
0.474889
&lt;/td&gt;
&lt;td&gt;
26.8343
&lt;/td&gt;
&lt;td&gt;
17.4861
&lt;/td&gt;
&lt;td&gt;
16.65897
&lt;/td&gt;
&lt;td&gt;
-29.031888
&lt;/td&gt;
&lt;td&gt;
19.2221
&lt;/td&gt;
&lt;td&gt;
Abnormal
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
69.297008
&lt;/td&gt;
&lt;td&gt;
24.652878
&lt;/td&gt;
&lt;td&gt;
44.311238
&lt;/td&gt;
&lt;td&gt;
44.644130
&lt;/td&gt;
&lt;td&gt;
101.868495
&lt;/td&gt;
&lt;td&gt;
11.211523
&lt;/td&gt;
&lt;td&gt;
0.369345
&lt;/td&gt;
&lt;td&gt;
23.5603
&lt;/td&gt;
&lt;td&gt;
12.7074
&lt;/td&gt;
&lt;td&gt;
11.42447
&lt;/td&gt;
&lt;td&gt;
-30.470246
&lt;/td&gt;
&lt;td&gt;
18.8329
&lt;/td&gt;
&lt;td&gt;
Abnormal
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
49.712859
&lt;/td&gt;
&lt;td&gt;
9.652075
&lt;/td&gt;
&lt;td&gt;
28.317406
&lt;/td&gt;
&lt;td&gt;
40.060784
&lt;/td&gt;
&lt;td&gt;
108.168725
&lt;/td&gt;
&lt;td&gt;
7.918501
&lt;/td&gt;
&lt;td&gt;
0.543360
&lt;/td&gt;
&lt;td&gt;
35.4940
&lt;/td&gt;
&lt;td&gt;
15.9546
&lt;/td&gt;
&lt;td&gt;
8.87237
&lt;/td&gt;
&lt;td&gt;
-16.378376
&lt;/td&gt;
&lt;td&gt;
24.9171
&lt;/td&gt;
&lt;td&gt;
Abnormal
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;exploration-of-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Exploration of the data&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Letâs check if there are some missing values in this dataset.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data.info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;    &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
    RangeIndex: 310 entries, 0 to 309
    Data columns (total 13 columns):
    pelvic_incidence            310 non-null float64
    pelvic_tilt                 310 non-null float64
    lumbar_lordosis_angle       310 non-null float64
    sacral_slope                310 non-null float64
    pelvic_radius               310 non-null float64
    degree_spondylolisthesis    310 non-null float64
    pelvic_slope                310 non-null float64
    direct_tilt                 310 non-null float64
    thoracic_slope              310 non-null float64
    cervical_tilt               310 non-null float64
    sacrum_angle                310 non-null float64
    scoliosis_slope             310 non-null float64
    class                       310 non-null object
    dtypes: float64(12), object(1)
    memory usage: 31.6+ KB&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Compute some basic statistics about the data.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data.describe()&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;overflow-x:auto;&#34;&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
&lt;/th&gt;
&lt;th&gt;
Pelvic Incidence
&lt;/th&gt;
&lt;th&gt;
Pelvic Tilt
&lt;/th&gt;
&lt;th&gt;
Lumbar Lordosis Angle
&lt;/th&gt;
&lt;th&gt;
Sacral Slope
&lt;/th&gt;
&lt;th&gt;
Pelvic Radius
&lt;/th&gt;
&lt;th&gt;
Degree Spondylolisthesis
&lt;/th&gt;
&lt;th&gt;
Pelvic Slope
&lt;/th&gt;
&lt;th&gt;
Direct Tilt
&lt;/th&gt;
&lt;th&gt;
Thoracic Slope
&lt;/th&gt;
&lt;th&gt;
Cervical Tilt
&lt;/th&gt;
&lt;th&gt;
Sacrum Angle
&lt;/th&gt;
&lt;th&gt;
Scoliosis Slope
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;
Count
&lt;/th&gt;
&lt;td&gt;
310.000000
&lt;/td&gt;
&lt;td&gt;
310.000000
&lt;/td&gt;
&lt;td&gt;
310.000000
&lt;/td&gt;
&lt;td&gt;
310.000000
&lt;/td&gt;
&lt;td&gt;
310.000000
&lt;/td&gt;
&lt;td&gt;
310.000000
&lt;/td&gt;
&lt;td&gt;
310.000000
&lt;/td&gt;
&lt;td&gt;
310.000000
&lt;/td&gt;
&lt;td&gt;
310.000000
&lt;/td&gt;
&lt;td&gt;
310.000000
&lt;/td&gt;
&lt;td&gt;
310.000000
&lt;/td&gt;
&lt;td&gt;
310.000000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
Mean
&lt;/th&gt;
&lt;td&gt;
60.496653
&lt;/td&gt;
&lt;td&gt;
17.542822
&lt;/td&gt;
&lt;td&gt;
51.930930
&lt;/td&gt;
&lt;td&gt;
42.953831
&lt;/td&gt;
&lt;td&gt;
117.920655
&lt;/td&gt;
&lt;td&gt;
26.296694
&lt;/td&gt;
&lt;td&gt;
0.472979
&lt;/td&gt;
&lt;td&gt;
21.321526
&lt;/td&gt;
&lt;td&gt;
13.064511
&lt;/td&gt;
&lt;td&gt;
11.933317
&lt;/td&gt;
&lt;td&gt;
-14.053139
&lt;/td&gt;
&lt;td&gt;
25.645981
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
Std
&lt;/th&gt;
&lt;td&gt;
17.236520
&lt;/td&gt;
&lt;td&gt;
10.008330
&lt;/td&gt;
&lt;td&gt;
18.554064
&lt;/td&gt;
&lt;td&gt;
13.423102
&lt;/td&gt;
&lt;td&gt;
13.317377
&lt;/td&gt;
&lt;td&gt;
37.559027
&lt;/td&gt;
&lt;td&gt;
0.285787
&lt;/td&gt;
&lt;td&gt;
8.639423
&lt;/td&gt;
&lt;td&gt;
3.399713
&lt;/td&gt;
&lt;td&gt;
2.893265
&lt;/td&gt;
&lt;td&gt;
12.225582
&lt;/td&gt;
&lt;td&gt;
10.450558
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
Min
&lt;/th&gt;
&lt;td&gt;
26.147921
&lt;/td&gt;
&lt;td&gt;
-6.554948
&lt;/td&gt;
&lt;td&gt;
14.000000
&lt;/td&gt;
&lt;td&gt;
13.366931
&lt;/td&gt;
&lt;td&gt;
70.082575
&lt;/td&gt;
&lt;td&gt;
-11.058179
&lt;/td&gt;
&lt;td&gt;
0.003220
&lt;/td&gt;
&lt;td&gt;
7.027000
&lt;/td&gt;
&lt;td&gt;
7.037800
&lt;/td&gt;
&lt;td&gt;
7.030600
&lt;/td&gt;
&lt;td&gt;
-35.287375
&lt;/td&gt;
&lt;td&gt;
7.007900
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
25%
&lt;/th&gt;
&lt;td&gt;
46.430294
&lt;/td&gt;
&lt;td&gt;
10.667069
&lt;/td&gt;
&lt;td&gt;
37.000000
&lt;/td&gt;
&lt;td&gt;
33.347122
&lt;/td&gt;
&lt;td&gt;
110.709196
&lt;/td&gt;
&lt;td&gt;
1.603727
&lt;/td&gt;
&lt;td&gt;
0.224367
&lt;/td&gt;
&lt;td&gt;
13.054400
&lt;/td&gt;
&lt;td&gt;
10.417800
&lt;/td&gt;
&lt;td&gt;
9.541140
&lt;/td&gt;
&lt;td&gt;
-24.289522
&lt;/td&gt;
&lt;td&gt;
17.189075
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
50%
&lt;/th&gt;
&lt;td&gt;
58.691038
&lt;/td&gt;
&lt;td&gt;
16.357689
&lt;/td&gt;
&lt;td&gt;
49.562398
&lt;/td&gt;
&lt;td&gt;
42.404912
&lt;/td&gt;
&lt;td&gt;
118.268178
&lt;/td&gt;
&lt;td&gt;
11.767934
&lt;/td&gt;
&lt;td&gt;
0.475989
&lt;/td&gt;
&lt;td&gt;
21.907150
&lt;/td&gt;
&lt;td&gt;
12.938450
&lt;/td&gt;
&lt;td&gt;
11.953835
&lt;/td&gt;
&lt;td&gt;
-14.622856
&lt;/td&gt;
&lt;td&gt;
24.931950
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
75%
&lt;/th&gt;
&lt;td&gt;
72.877696
&lt;/td&gt;
&lt;td&gt;
22.120395
&lt;/td&gt;
&lt;td&gt;
63.000000
&lt;/td&gt;
&lt;td&gt;
52.695888
&lt;/td&gt;
&lt;td&gt;
125.467674
&lt;/td&gt;
&lt;td&gt;
41.287352
&lt;/td&gt;
&lt;td&gt;
0.704846
&lt;/td&gt;
&lt;td&gt;
28.954075
&lt;/td&gt;
&lt;td&gt;
15.889525
&lt;/td&gt;
&lt;td&gt;
14.371810
&lt;/td&gt;
&lt;td&gt;
-3.497094
&lt;/td&gt;
&lt;td&gt;
33.979600
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;
Max
&lt;/th&gt;
&lt;td&gt;
129.834041
&lt;/td&gt;
&lt;td&gt;
49.431864
&lt;/td&gt;
&lt;td&gt;
125.742385
&lt;/td&gt;
&lt;td&gt;
121.429566
&lt;/td&gt;
&lt;td&gt;
163.071041
&lt;/td&gt;
&lt;td&gt;
418.543082
&lt;/td&gt;
&lt;td&gt;
0.998827
&lt;/td&gt;
&lt;td&gt;
36.743900
&lt;/td&gt;
&lt;td&gt;
19.324000
&lt;/td&gt;
&lt;td&gt;
16.821080
&lt;/td&gt;
&lt;td&gt;
6.972071
&lt;/td&gt;
&lt;td&gt;
44.341200
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;No results seem to be unusual, except for the maximum of the &lt;em&gt;Degree Spondylolisthesis&lt;/em&gt;. Usually, a degree is between -180Â° and 180Â° (or 0Â° and 360Â°). If we look at the other data, it seems that the coding of the angle is between -180Â° and 180Â° (with a very few negative angle). Letâs look at all the values out of the usual range of the degrees (it concerns only the variable &lt;em&gt;Degree Spondylolisthesis&lt;/em&gt;).&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data[data.degree_spondylolisthesis &amp;gt; 180]&lt;/code&gt;&lt;/pre&gt;
&lt;div style=&#34;overflow-x:auto;&#34;&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table class=&#34;dataframe&#34;&gt;
&lt;thead&gt;
&lt;tr style=&#34;text-align: right;&#34;&gt;
&lt;th&gt;
&lt;/th&gt;
&lt;th&gt;
Pelvic Incidence
&lt;/th&gt;
&lt;th&gt;
Pelvic Tilt
&lt;/th&gt;
&lt;th&gt;
Lumbar Lordosis Angle
&lt;/th&gt;
&lt;th&gt;
Sacral Slope
&lt;/th&gt;
&lt;th&gt;
Pelvic Radius
&lt;/th&gt;
&lt;th&gt;
Degree Spondylolisthesis
&lt;/th&gt;
&lt;th&gt;
Pelvic Slope
&lt;/th&gt;
&lt;th&gt;
Direct Tilt
&lt;/th&gt;
&lt;th&gt;
Thoracic Slope
&lt;/th&gt;
&lt;th&gt;
Cervical Tilt
&lt;/th&gt;
&lt;th&gt;
Sacrum Angle
&lt;/th&gt;
&lt;th&gt;
Scoliosis Slope
&lt;/th&gt;
&lt;th&gt;
Class
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;
115
&lt;/th&gt;
&lt;td&gt;
129.834041
&lt;/td&gt;
&lt;td&gt;
8.404475
&lt;/td&gt;
&lt;td&gt;
48.384057
&lt;/td&gt;
&lt;td&gt;
121.429566
&lt;/td&gt;
&lt;td&gt;
107.690466
&lt;/td&gt;
&lt;td&gt;
418.543082
&lt;/td&gt;
&lt;td&gt;
0.860223
&lt;/td&gt;
&lt;td&gt;
18.5943
&lt;/td&gt;
&lt;td&gt;
11.1514
&lt;/td&gt;
&lt;td&gt;
11.36543
&lt;/td&gt;
&lt;td&gt;
-34.202073
&lt;/td&gt;
&lt;td&gt;
27.5144
&lt;/td&gt;
&lt;td&gt;
Abnormal
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;Only one observation has a &lt;em&gt;Degree Spondylolisthesis&lt;/em&gt; larger than 180. We can consider a typo in the decimal of this value. So, we replace the value 418.543082 by 41.8543082.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data.loc[115, &amp;#39;degree_spondylolisthesis&amp;#39;] = 41.8543082&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Recode the variable &lt;em&gt;class&lt;/em&gt; into a dummy variable (0: Abnormal, 1: Normal).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data[&amp;#39;class&amp;#39;] = pd.get_dummies(data[&amp;#39;class&amp;#39;], prefix=&amp;#39;class&amp;#39;, drop_first=True)&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Then, we look at the correlation between the different variables.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Compute the correlation matrix.
corr_data = round(data.corr(),2)&lt;/code&gt;&lt;/pre&gt;
&lt;center&gt;
&lt;img src=&#34;output_15_0.png&#34; title=&#34;fig:&#34; alt=&#34;png&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;So, it appears that the class {Abnormal, Normal} is negatively correlated with the &lt;em&gt;Pelvic Incidence&lt;/em&gt;, the &lt;em&gt;Pelvic Tilt&lt;/em&gt;, the &lt;em&gt;Lumbar Lordosis Angle&lt;/em&gt;, the &lt;em&gt;Sacral Slope&lt;/em&gt; and the &lt;em&gt;Degree Spondylolisthesis&lt;/em&gt; and positively correlated with the &lt;em&gt;Pelvic Radius&lt;/em&gt;. The class has a very small correlation with the other variables.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Letâs look at some boxplot for these variables.&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src=&#34;output_18_0.png&#34; title=&#34;fig:&#34; alt=&#34;png&#34; /&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;div id=&#34;subset-features-selection&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Subset features selection&lt;/h1&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;model = ExtraTreesClassifier(n_estimators=200, random_state=0)
model.fit(data.drop(&amp;#39;class&amp;#39;, axis=1, inplace=False), data[&amp;#39;class&amp;#39;])

importances = model.feature_importances_
importances_std = np.std([model_tree.feature_importances_ for model_tree in model.estimators_], axis=0)&lt;/code&gt;&lt;/pre&gt;
&lt;center&gt;
&lt;img src=&#34;output_21_0.png&#34; title=&#34;fig:&#34; alt=&#34;png&#34; /&gt;
&lt;/center&gt;
&lt;p&gt;So, we have an importance score for each attribute where the larger score the more important the attribute. As we see on the correlation plot, the variable &lt;em&gt;degree spondylolisthesis&lt;/em&gt; and &lt;em&gt;pelvic radius&lt;/em&gt;/&lt;em&gt;pelvic tilt&lt;/em&gt;/&lt;em&gt;pelvic incidence&lt;/em&gt;/&lt;em&gt;lumbar lordosis angle&lt;/em&gt; are strongly correlated. We will consider only the variables &lt;em&gt;Degree Spondylolisthesis&lt;/em&gt;, &lt;em&gt;Pelvic Radius&lt;/em&gt;, &lt;em&gt;Pelvic Tilt&lt;/em&gt; and &lt;em&gt;Pelvic Incidence&lt;/em&gt; for building the model (the four with the strongest importance).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Letâs plot these variables with the class.&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src=&#34;output_24_0.png&#34; title=&#34;fig:&#34; alt=&#34;png&#34; /&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;div id=&#34;model-construction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model construction&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Split the dataset into train and test set.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;X_train, X_test, Y_train, Y_test = train_test_split(data[[&amp;#39;degree_spondylolisthesis&amp;#39;, &amp;#39;pelvic_radius&amp;#39;, &amp;#39;pelvic_tilt&amp;#39;, &amp;#39;pelvic_incidence&amp;#39;]], data[&amp;#39;class&amp;#39;], test_size=1/3, random_state=42)

scaler = StandardScaler().fit(X_train)
X_train_transformed = scaler.transform(X_train)
X_test_transformed = scaler.transform(X_test)&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Letâs construct the baseline by setting the most frequent response in the training set to compare our model.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;dummy = DummyClassifier(strategy=&amp;#39;most_frequent&amp;#39;, random_state=42)
dummy.fit(X_train_transformed, Y_train)
Y_pred_dummy = dummy.predict(X_test_transformed)

Y_pred_proba_dummy = dummy.predict_proba(X_test_transformed)[:, 1]
[fpr_dummy, tpr_dummy, thr_dummy] = metrics.roc_curve(Y_test, Y_pred_proba_dummy)&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;The accuracy for the dummy classifier is 72%.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Use the Logistic Regression method to predict the class (by Cross-Validation and GridSearch).&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;param_log_reg = {&amp;#39;tol&amp;#39;: np.logspace(-5, 1, 7),
                 &amp;#39;C&amp;#39;: np.logspace(-3, 3, 7),
                 &amp;#39;penalty&amp;#39;: [&amp;#39;l2&amp;#39;]}

log_reg = GridSearchCV(LogisticRegression(solver=&amp;#39;lbfgs&amp;#39;), param_log_reg, cv=10, iid=False)
log_reg.fit(X_train_transformed, Y_train)&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Best parameters set found on development set: {âCâ: 1.0, âpenaltyâ: âl2â, âtolâ: 1.0}&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;Y_pred_log_reg = log_reg.predict(X_test_transformed)

Y_pred_proba_log_reg = log_reg.predict_proba(X_test_transformed)[:, 1]
[fpr_log_reg, tpr_log_reg, thr_log_reg] = metrics.roc_curve(Y_test, Y_pred_proba_log_reg)&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;The accuracy for the Logistic Regression classifier is 85%.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Plot the ROC curves for each models&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src=&#34;output_34_0.png&#34; title=&#34;fig:&#34; alt=&#34;png&#34; /&gt;
&lt;/center&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Package ggplot2</title>
      <link>/post/package-ggplot2/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/post/package-ggplot2/</guid>
      <description>&lt;p&gt;The package &lt;code&gt;ggplot2&lt;/code&gt; has been created by Hadley Wickham among others. It is disponible on the 
&lt;a href=&#34;https://cloud.r-project.org/web/packages/ggplot2/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN&lt;/a&gt;
. Check out the official 
&lt;a href=&#34;https://cloud.r-project.org/web/packages/ggplot2/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;website&lt;/a&gt;
 for more information. It is designed to provide nice graphics in an quite easy way.&lt;/p&gt;
&lt;h2 id=&#34;use-custom-theme&#34;&gt;Use custom theme&lt;/h2&gt;
&lt;p&gt;First, define a particular function that define a new theme based on another.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34;&gt;theme_custom = function(base_family = &amp;quot;Times&amp;quot;){
  theme_minimal(base_family = base_family) %+replace%
    theme(
      plot.title = element_text(size = 20),
      plot.subtitle = element_text(size = 16, vjust = -1),
      
      axis.title = element_text(size = 18),
      axis.text = element_text(size = 16),
      
      axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0), angle = 90),
      axis.title.x = element_text(margin = margin(t = 20, r = 0, b = 20, l = 0)),
      
      strip.text.x = element_text(size = 16),
      strip.text.y = element_text(size = 16),
      
      legend.text = element_text(size = 18),
      legend.text.align = 0
    )
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, just use it as any other theme.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-{r&#34;&gt;ggplot(aes(x, y)) + theme_custom()
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Set up Hive</title>
      <link>/post/set-up-hive/</link>
      <pubDate>Sun, 09 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/post/set-up-hive/</guid>
      <description>&lt;h2 id=&#34;set-up-on-macos&#34;&gt;Set up on MacOs&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s install &lt;strong&gt;Hive&lt;/strong&gt; with &lt;strong&gt;Homebrew.&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install hive
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;strong&gt;Hive&lt;/strong&gt;&amp;lsquo;s files are in the folder &lt;code&gt;/usr/local/Cellar/hive/*&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Same as &lt;strong&gt;Hadoop&lt;/strong&gt;, add some environment variables to the &lt;code&gt;.bashrc&lt;/code&gt;file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Hive environment
export HIVE_HOME=/usr/local/Cellar/hive/*/libexec
PATH=$HIVE_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to launch Hive, Hadoop ressources must be set up.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Setup Hadoop
$HADOOP_HOME/sbin/start-dfs.sh
$HADOOP_HOME/sbin/start-yarn.sh
# Launch Hive
hive
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;common-errors&#34;&gt;Common errors&lt;/h2&gt;
&lt;h3 id=&#34;metastore-troubles&#34;&gt;Metastore troubles&lt;/h3&gt;
&lt;p&gt;Just remove and reload the metastore.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;rm -rf metastore_db derby.log
$HIVE_HOME/bin/schematool -initSchema -dbType derby
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Set up Spark</title>
      <link>/post/set-up-spark/</link>
      <pubDate>Sun, 09 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/post/set-up-spark/</guid>
      <description>&lt;h2 id=&#34;set-up-on-macos&#34;&gt;Set up on MacOs&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s install &lt;strong&gt;Spark&lt;/strong&gt; with &lt;strong&gt;Homebrew.&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install apache-spark
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;strong&gt;Spark&lt;/strong&gt;&amp;lsquo;s files are in the folder &lt;code&gt;/usr/local/Cellar/apache-spark/*&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Same as &lt;strong&gt;Hadoop&lt;/strong&gt;, add some environment variables to the &lt;code&gt;.bashrc&lt;/code&gt;file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Spark environment
export SPARK_HOME=/usr/local/Cellar/apache-spark/*/libexec
PATH=$SPARK_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;configure-spark-to-run-with-yarn&#34;&gt;Configure Spark to run with YARN&lt;/h2&gt;
&lt;p&gt;Edit the file &lt;code&gt;$SPARK_HOME/conf/spark-env.sh.template&lt;/code&gt; by adding the following line:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then rename it as &lt;code&gt;spark-env.sh&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Finally, you can run the Spark command lines on YARN with the command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;spark-shell --master yarn --deploy-mode client
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Set up Hadoop</title>
      <link>/post/hadoop/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/post/hadoop/</guid>
      <description>&lt;h2 id=&#34;hadoop-deployment-modes&#34;&gt;Hadoop deployment modes&lt;/h2&gt;
&lt;p&gt;There are three ways to deploy Hadoop:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Local mode&lt;/li&gt;
&lt;li&gt;Pseudo-distributed mode&lt;/li&gt;
&lt;li&gt;Distributed mode&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;requisites-to-the-installation&#34;&gt;Requisites to the installation&lt;/h2&gt;
&lt;h3 id=&#34;java&#34;&gt;Java&lt;/h3&gt;
&lt;p&gt;Check if &lt;strong&gt;Java&lt;/strong&gt; is installed:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;java -version
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It should return something like that:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;java version &amp;quot;1.8.0_***&amp;quot;
Java(TM) SE Runtime Environment (build 1.8.0_***-b11)
Java HotSpot(TM) 64-Bit Server VM (build 25.***-b11, mixed mode)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If not, you could go on 
&lt;a href=&#34;https://www.java.com/fr/download/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;java.com&lt;/a&gt;
 and download it.&lt;/p&gt;
&lt;h3 id=&#34;ssh&#34;&gt;SSH&lt;/h3&gt;
&lt;p&gt;On MacOS, the &lt;strong&gt;Remote Login&lt;/strong&gt; must be enable to authorise SSH. It is located in &lt;strong&gt;Systeme Preference&lt;/strong&gt; and &lt;strong&gt;Sharing&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Try to ssh to &lt;em&gt;localhost&lt;/em&gt; without a passphrase/password. This is important because we do not want to enter a passphrase/password every time Hadoop connect to a node.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh localhost
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you can not, run these commands to create a key and put it into the authorised one to connect.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ssh-keygen -t rsa -P &amp;quot;&amp;quot;
cat ~/.ssh/id_rsa.pub &amp;gt;&amp;gt; ~/.ssh/authorized_keys
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;set-up-on-macos&#34;&gt;Set up on MacOs&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s install Hadoop with Homebrew.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install hadoop
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a result, we see where are Hadoop&amp;rsquo;s config files:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;/usr/local/opt/hadoop/libexec/etc/hadoop/hadoop-env.sh
/usr/local/opt/hadoop/libexec/etc/hadoop/mapred-env.sh
/usr/local/opt/hadoop/libexec/etc/hadoop/yarn-env.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Moreover, the &lt;code&gt;JAVA_HOME&lt;/code&gt; has been set to the result of the command &lt;code&gt;/usr/libexec/java_home&lt;/code&gt;.
And finally, the Hadoop&amp;rsquo;s files are in the folder &lt;code&gt;/usr/local/Cellar/hadoop/*&lt;/code&gt;.
Now, in order to simplify the commands, it is common to add some environment variables to the &lt;code&gt;.bashrc&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Hadoop environment
export HADOOP_HOME=/usr/local/Cellar/hadoop/*/libexec
PATH=$HADOOP_HOME/bin:$PATH
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;configure-hdfs-for-the-pseudo-distributed-mode&#34;&gt;Configure HDFS for the Pseudo-Distributed mode&lt;/h3&gt;
&lt;h4 id=&#34;use-a-single-datanode-for-each-block&#34;&gt;Use a single DataNode for each block&lt;/h4&gt;
&lt;p&gt;Add the following lines to the file &lt;code&gt;$HADOOP_HOME/etc/hadoop/hdfs-site.xml&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;configure-the-namenode-port&#34;&gt;Configure the NameNode port&lt;/h4&gt;
&lt;p&gt;Add the following lines to the file &lt;code&gt;$HADOOP_HOME/etc/hadoop/core-site.xml&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;set-the-runtime-framework-for-executing-mapreduce-jobs&#34;&gt;Set the runtime framework for executing MapReduce jobs&lt;/h4&gt;
&lt;p&gt;Add the following lines to the file &lt;code&gt;$HADOOP_HOME/etc/hadoop/mapred-site.xml&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;implement-the-service-_mapreduce_shuffle_&#34;&gt;Implement the service &lt;em&gt;mapreduce_shuffle&lt;/em&gt;.&lt;/h4&gt;
&lt;p&gt;Add the following lines to the file &lt;code&gt;$HADOOP_HOME/etc/hadoop/yarn-site.xml&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;format-the-filesystem&#34;&gt;Format the filesystem&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, you can start the NameNode and DataNode deamons.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$HADOOP_HOME/sbin/start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is possible to check if it&amp;rsquo;s working using the UI interface: 
&lt;a href=&#34;http://localhost:50070/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://localhost:50070/&lt;/a&gt;
 or 
&lt;a href=&#34;http://localhost:9870/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://localhost:9870/&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;And start the Ressource and Node managers.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$HADOOP_HOME/sbin/start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is possible to check if it&amp;rsquo;s working using the UI interface: 
&lt;a href=&#34;http://localhost:8088/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://localhost:8088/&lt;/a&gt;
.&lt;/p&gt;
&lt;h2 id=&#34;common-errors&#34;&gt;Common Errors&lt;/h2&gt;
&lt;h3 id=&#34;incompatible-clusterids&#34;&gt;Incompatible clusterIDs&lt;/h3&gt;
&lt;p&gt;You should reformat the name node with the right clusterId.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hdfs namenode -format -clusterId CID-...
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Jupyter Notebook</title>
      <link>/post/jupyter-notebook/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/post/jupyter-notebook/</guid>
      <description>&lt;h2 id=&#34;update-irkernel-after-updating-r&#34;&gt;Update IRkernel after updating R&lt;/h2&gt;
&lt;p&gt;Modify the file &lt;code&gt;kernel.json&lt;/code&gt; into the folder &lt;code&gt;~/Library/Jupyter/kernels/ir&lt;/code&gt;.
Replace the value of the argument &lt;code&gt;argv&lt;/code&gt; by the new path of R.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Homebrew</title>
      <link>/post/homebrew/</link>
      <pubDate>Thu, 06 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/post/homebrew/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://brew.sh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Homebrew&lt;/a&gt;
 names itself as &lt;em&gt;the missing package manager for macOS&lt;/em&gt;. It simplifies the installation and the management of the different softwares you could have.&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;First, you need to have the &lt;strong&gt;Command Line Tools&lt;/strong&gt; for &lt;strong&gt;Xcode&lt;/strong&gt;. The installation of &lt;strong&gt;Xcode&lt;/strong&gt; is made from the App Store. Once it is done, you can install the &lt;strong&gt;Command Line Tools&lt;/strong&gt; using the following command in the terminal:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;xcode-select --install
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, you should launch the following command to have &lt;strong&gt;Homebrew&lt;/strong&gt; installed:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After, you should tell to the system to take into consideration programs installed by &lt;strong&gt;Homebrew&lt;/strong&gt; rather than the system default. By default, &lt;strong&gt;Homebrew&lt;/strong&gt; uses the &lt;code&gt;/usr/local/bin&lt;/code&gt; path. We do this by the adding this path to the &lt;code&gt;$PATH&lt;/code&gt; environment variable.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &#39;export PATH=&amp;quot;/usr/local/bin/:$PATH&amp;quot;&#39; &amp;gt;&amp;gt; ~/.bash_profile
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;usage&#34;&gt;Usage&lt;/h2&gt;
&lt;p&gt;We install and uninstall a formula by using the commands:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install &amp;lt;formula&amp;gt;
brew uninstall &amp;lt;formula&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To upgrade all the formulae, run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew update
brew upgrade
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To list all the formulae you have with their version, run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew list --versions
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, &lt;strong&gt;Homebrew&lt;/strong&gt; keeps a trace of the previous versions of each of the formula (if you want to get it back). If you want to delete it, run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew cleanup
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;cask&#34;&gt;Cask&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://caskroom.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Homebrew-Cask&lt;/a&gt;
 extends &lt;strong&gt;Homebrew&lt;/strong&gt; and allows to install software using command-line tools.&lt;/p&gt;
&lt;p&gt;To look for a software, run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew cask search &amp;lt;formula&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To install/uninstall a software, run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew cask install &amp;lt;formula&amp;gt;
brew cask uninstall &amp;lt;formula&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To know the outdated formulae, run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew cask outdated
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then, for update the package, run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew cask reinstall &amp;lt;formula&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Library Matplotlib</title>
      <link>/post/library-matplotlib/</link>
      <pubDate>Thu, 06 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/post/library-matplotlib/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;http://matplotlib.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Matplotlib&lt;/a&gt;
 is a Python 2D plotting library.&lt;/p&gt;
&lt;h2 id=&#34;use-another-font&#34;&gt;Use another font&lt;/h2&gt;
&lt;p&gt;First, you need to download/get back the font in the &lt;code&gt;ttf&lt;/code&gt; format. Once it is done, you have to find out the location of the matplotlib library.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -c &amp;quot;import matplotlib; print(matplotlib.matplotlib_fname())&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This folder will be different for everyone depending on the installation but it should ended by &lt;code&gt;/matplotlib/mpl-data/matplotlibrc&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Then, you copy the font into the folder &lt;code&gt;/matplotlib/mpl-data/fonts/ttf/&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp font.ttf ./matplotlib/mpl-data/fonts/ttf/
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, remove the font cache:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;rm ~/.matplotlib/fontList.py3k.cache
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, you can use the new font:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import matplotlib.pyplot as plt
plt.rc(&#39;font&#39;, family=&#39;font_name&#39;)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>MySQL</title>
      <link>/post/mysql/</link>
      <pubDate>Thu, 06 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/post/mysql/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://www.mysql.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MySQL&lt;/a&gt;
 is an open-source relational database management system.&lt;/p&gt;
&lt;h2 id=&#34;installation-and-configurations&#34;&gt;Installation and configurations&lt;/h2&gt;
&lt;p&gt;We simply use &lt;strong&gt;Homebrew&lt;/strong&gt; to install &lt;strong&gt;MySQL&lt;/strong&gt; under MacOS.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install mysql
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, we can launch &lt;strong&gt;MySQL&lt;/strong&gt; by running the command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew services start mysql
# ==&amp;gt; Successfully started &#39;mysql&#39; (label: homebrew.mxcl.mysql)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One can recommended to set a password for the &lt;em&gt;root&lt;/em&gt; user and only authorize the access from &lt;em&gt;localhost&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mysql_secure_installation
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then, we re-launch &lt;strong&gt;MySQL&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew services restart mysql
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;connection&#34;&gt;Connection&lt;/h2&gt;
&lt;p&gt;We connect to &lt;strong&gt;MySQL&lt;/strong&gt; by running the commands:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mysql --host=localhost --user=root -p
# Enter password : ****
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is not recommended to work in &lt;em&gt;root&lt;/em&gt; on databases because this user has all privileges. One could create a restrictive user of the database.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;GRANT ALL PRIVILEGES ON nom_base.* TO &#39;name&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;password&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One can save the database into a file using the command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mysqldump -u user -p --opt database_name &amp;gt; save.sql
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;configuration&#34;&gt;Configuration&lt;/h2&gt;
&lt;p&gt;In order to use every possible characters into the string in the database, one should activate the UTF-8 encode.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mysql --host=localhost --user=name -p --default_character-set=utf8
# Enter password : ****
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to insert data into the database using external files, one should activate this possibility.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mysql -h localhost -u name -p --enable-local-infile
# Enter password : ****
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Package xml2</title>
      <link>/post/package-xml2/</link>
      <pubDate>Thu, 06 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/post/package-xml2/</guid>
      <description>&lt;p&gt;The package &lt;code&gt;xml2&lt;/code&gt; has been created by Hadley Wickham among others. It is disponible on the 
&lt;a href=&#34;https://cran.r-project.org/web/packages/xml2/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRAN&lt;/a&gt;
. It is designed to work with XML files in &lt;strong&gt;R&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;installation-issues&#34;&gt;Installation issues&lt;/h2&gt;
&lt;h3 id=&#34;configuration-failed-because-libxml-20-was-not-found&#34;&gt;Configuration failed because libxml-2.0 was not found&lt;/h3&gt;
&lt;p&gt;First, check that the folders given by the following commands exits:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;which xml2-config
# /usr/bin/xml2-config

xml2-config --libs
# -L/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/lib -lxml2 -lz -lpthread -licucore -lm

xml2-config --cflags
# -I/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.13.sdk/usr/include/libxml2

which pkg-config
# /usr/local/bin/pkg-config

pkg-config --cflags libxml-2.0
# -I/usr/include/libxml2

pkg-config --libs libxml-2.0
# -lxml2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the case where, &lt;code&gt;/usr/include&lt;/code&gt; does not exists, run the command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;xcode-select --install
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then, re-try to install the package &lt;code&gt;xml2&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Set up Python</title>
      <link>/post/set-up-python/</link>
      <pubDate>Thu, 06 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/post/set-up-python/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://www.python.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Python&lt;/a&gt;
 is already installed on macOS. But as we do not want to mess with it, and have more flexibility, we will install our own version of &lt;strong&gt;Python&lt;/strong&gt;. This post is based on this 
&lt;a href=&#34;https://medium.com/@henriquebastos/the-definitive-guide-to-setup-my-python-workspace-628d68552e14&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;post&lt;/a&gt;
 by Henrique Bastos on Medium.&lt;/p&gt;
&lt;h2 id=&#34;wanted-configurations&#34;&gt;Wanted configurations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPython 2.7&lt;/strong&gt; and &lt;strong&gt;CPython 3.7&lt;/strong&gt;, but it is possible to install other implementations like &lt;strong&gt;PyPy&lt;/strong&gt; or &lt;strong&gt;Anaconda&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Python3&lt;/strong&gt; as a default version for everything, but it must easily change to &lt;strong&gt;Python2&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;A &lt;em&gt;unique&lt;/em&gt; &lt;strong&gt;Jupyter Notebook/Lab&lt;/strong&gt; working with both &lt;strong&gt;Python2&lt;/strong&gt; and &lt;strong&gt;Python3&lt;/strong&gt;, and being able to detect the active virtual environment.&lt;/li&gt;
&lt;li&gt;A console &lt;em&gt;iPython&lt;/em&gt; for &lt;strong&gt;Python3&lt;/strong&gt; and one for &lt;strong&gt;Python2&lt;/strong&gt;, so no need to install it in every virtual environment of the projects.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;virtualenvwrapper&lt;/em&gt; to develop the different projects and change the context in one command.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;pyenv&lt;/em&gt; is probably the best way to install &lt;strong&gt;Python&lt;/strong&gt; on macOS. Everything should be installed in the common directory without interfering with the rest of the system. Moreover, it handles with a lot of &lt;strong&gt;Python&lt;/strong&gt; implementation such as &lt;strong&gt;CPython&lt;/strong&gt;, &lt;strong&gt;PyPy&lt;/strong&gt;, &lt;strong&gt;Anaconda&lt;/strong&gt;, etc. And all of that with only one command. Firstly, one should install &lt;em&gt;pyenv&lt;/em&gt; and two add-ons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;pyenv&lt;/em&gt; to install &lt;strong&gt;Python&lt;/strong&gt; implementations;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;pyenv-virtualenv&lt;/em&gt; to configure global environment;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;pyenv-virtualenvwrapper&lt;/em&gt; to work on projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew install pyenv
brew install pyenv-virtualenv
brew install pyenv-virtualenvwrapper
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With &lt;em&gt;virtualenvwrapper&lt;/em&gt;, every &lt;em&gt;virtualenv&lt;/em&gt; will be kept in the same repository and every projects codes in an other.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Every virtual environment will be in ...
mkdir ~/.ve
# Every projects will be in ...
mkdir ~/Documents/Python/workspace
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have to configure the &lt;em&gt;shell&lt;/em&gt; to initialise &lt;em&gt;pyenv&lt;/em&gt; at the opening of the terminal. Thus, we have to add the following lines into the file &lt;code&gt;~/.bashrc&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export WORKON_HOME=~/.ve
export PROJECT_HOME=~/Documents/Python/workspace
eval &amp;quot;$(pyenv init -)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Reload the terminal to take the changes into account.&lt;/p&gt;
&lt;p&gt;Next step is to install &lt;strong&gt;CPython 3.7.1&lt;/strong&gt; and &lt;strong&gt;CPython 2.7.15&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pyenv install 3.7.1
pyenv install 2.7.15
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;configure-the-global-python-installation&#34;&gt;Configure the global Python installation&lt;/h2&gt;
&lt;p&gt;It is nice to use &lt;strong&gt;Python&lt;/strong&gt; written programs without using a virtual environment. Moreover, it is easier if we only have one &lt;em&gt;Jupyter Notebook/Lab&lt;/em&gt;, one &lt;em&gt;iPython console&lt;/em&gt; for &lt;strong&gt;Python 2&lt;/strong&gt;, one &lt;em&gt;iPython console&lt;/em&gt; for &lt;strong&gt;Python 3&lt;/strong&gt; and other tools.&lt;/p&gt;
&lt;p&gt;So, we use &lt;em&gt;pyenv-virtualenv&lt;/em&gt; to do that:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pyenv virtualenv 3.7.1 jupyter3
pyenv virtualenv 3.7.1 tools3
pyenv virtualenv 2.7.15 ipython2
pyenv virtualenv 2.7.15 tools2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Jupyter&lt;/em&gt; can handle with many kernels like &lt;strong&gt;Python 2&lt;/strong&gt;, &lt;strong&gt;Python 3&lt;/strong&gt;, &lt;strong&gt;R&lt;/strong&gt;, &lt;strong&gt;bash&lt;/strong&gt;, and some other. It allows only one &lt;em&gt;Jupyter&lt;/em&gt; installation.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Here, we just want to use &lt;strong&gt;Python2&lt;/strong&gt; and &lt;strong&gt;Python3&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let&amp;rsquo;s start with &lt;strong&gt;Python3&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pyenv activate jupyter3
pip install jupyter
pip install jupyterlab
python -m ipykernel install --user
pyenv deactivate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s continue with &lt;strong&gt;Python2&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pyenv activate ipython2
pip install ipykernel
python -m ipykernel install --user
pyenv deactivate
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Note that when we install &lt;em&gt;Jupyter&lt;/em&gt; for &lt;strong&gt;Python3&lt;/strong&gt;, we install by default &lt;em&gt;iPython&lt;/em&gt; and the &lt;em&gt;kernel&lt;/em&gt;. For &lt;strong&gt;Python2&lt;/strong&gt;, we only need to install &lt;em&gt;iPython&lt;/em&gt; and the &lt;em&gt;kernel&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now, let&amp;rsquo;s install tools using &lt;strong&gt;Python3&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pyenv activate tools3
pip install youtube-dl rows
pyenv deactivate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s install tools which do not work with &lt;strong&gt;Python3&lt;/strong&gt; but only with &lt;strong&gt;Python2&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pyenv activate tools2
pip install rename
pyenv deactivate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, it is time to let all the &lt;strong&gt;Python&lt;/strong&gt; versions and the special virtual environments working together.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pyenv global 3.7.1 2.7.15 jupyter3 ipython2 tools3 tools2
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;Note that this command put priority in the &lt;code&gt;$PATH&lt;/code&gt; environment variable. Thus, it is possible to reach the scripts without activating virtual environments.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;using-virtual-environment&#34;&gt;Using virtual environment&lt;/h2&gt;
&lt;p&gt;We use &lt;em&gt;pyenv-virtualenvwrapper&lt;/em&gt; to create the virtual environment for each project. Now, he have to add the line &lt;code&gt;pyenv virtualenvwrapper_lazy&lt;/code&gt; in the file &lt;code&gt;~/.bashrc&lt;/code&gt; and then reload the terminal. When we start a new session, &lt;em&gt;pyenv-virtualenvwrapper&lt;/em&gt; will install the necessary dependencies of &lt;em&gt;virtualenvwrapper&lt;/em&gt; if they are not here. It is possible to use commands from &lt;em&gt;virtualenvwrapper&lt;/em&gt; and every virtual environment will be created by using &lt;strong&gt;Python&lt;/strong&gt; implementations installed from &lt;em&gt;pyenv&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Some examples:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Let&amp;rsquo;s say I want a new project &lt;em&gt;proj3&lt;/em&gt; using &lt;strong&gt;Python3&lt;/strong&gt;. The command &lt;code&gt;mkproject proj3&lt;/code&gt; will create a new virtual environment using &lt;strong&gt;Python3&lt;/strong&gt; (by default) in the repository &lt;code&gt;~/.ve/proj3&lt;/code&gt; and a project repository &lt;code&gt;~/Documents/Python/workspace/proj3&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let&amp;rsquo;s imagine I want to work on my project &lt;em&gt;proj3&lt;/em&gt;. Run the command &lt;code&gt;workon proj3&lt;/code&gt; will activate the virtual environment &lt;code&gt;~/.ve/proj3&lt;/code&gt; and change the working directory to &lt;code&gt;~/Documents/Python/workspace/proj3&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let&amp;rsquo;s clone a project names &lt;em&gt;proj2&lt;/em&gt; in the directory &lt;code&gt;~/Documents/Python/workspace/proj2&lt;/code&gt;. So, I need a virtual environment for this project. Run the command &lt;code&gt;mkvirtualenv -a ~/Documents/Python/workspace/proj2 -p python2 proj2&lt;/code&gt; will create a virtual environment using &lt;strong&gt;Python2&lt;/strong&gt; in the directory &lt;code&gt;~/.ve/proj2&lt;/code&gt; linked to the project. Then, run &lt;code&gt;workon proj2&lt;/code&gt; will activate the virtual environment and change the working directory.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;using-jupyter-and-ipython-with-the-projects&#34;&gt;Using Jupyter and iPython with the projects&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;At the beginning, &lt;em&gt;Jupyter&lt;/em&gt; and &lt;em&gt;Console&lt;/em&gt; were parts of &lt;em&gt;iPython&lt;/em&gt; project which was only about &lt;strong&gt;Python&lt;/strong&gt;. But the evolution of the &lt;em&gt;Notebook&lt;/em&gt; allows to use more languages than just &lt;strong&gt;Python&lt;/strong&gt;. So, the developers decide to split the project: &lt;em&gt;Jupyter&lt;/em&gt; and &lt;em&gt;iPython&lt;/em&gt;. Now, &lt;em&gt;Notebook&lt;/em&gt; is part of &lt;em&gt;Jupyter&lt;/em&gt; and &lt;em&gt;Console&lt;/em&gt; is part of &lt;em&gt;iPython&lt;/em&gt; and the &lt;em&gt;Python kernel&lt;/em&gt; used by &lt;em&gt;Jupyter&lt;/em&gt; to launch &lt;strong&gt;Python&lt;/strong&gt; code.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, &lt;em&gt;Jupyter&lt;/em&gt; do not detect the active virtual environment: it is the &lt;em&gt;iPython&lt;/em&gt; instance that &lt;em&gt;Jupyter&lt;/em&gt; initialize. The problem is that the &lt;em&gt;iPython&lt;/em&gt; virtual environment launches itself only in &lt;em&gt;interactive shell&lt;/em&gt; mode and not in &lt;em&gt;kernel&lt;/em&gt; mode. Otherwise, the code detection works correctly only if the &lt;strong&gt;Python&lt;/strong&gt; version of the active virtual environment and the &lt;strong&gt;Python&lt;/strong&gt; version launches by &lt;em&gt;iPython&lt;/em&gt; are the same.&lt;/p&gt;
&lt;p&gt;The solution is to customize the process of the &lt;em&gt;iPython&lt;/em&gt; start-up. To do that, we need a &lt;em&gt;iPython profile&lt;/em&gt; et launch a 
&lt;a href=&#34;https://gist.github.com/henriquebastos/270cff100cb303f3d74370489022446b&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;script&lt;/a&gt;
:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ipython profile create
curl -L http://hbn.link/hb-ipython-startup-script &amp;gt; ~/.ipython/profile_default/startup/00-venv-sitepackages.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, no matter the mode in which &lt;em&gt;iPython&lt;/em&gt; is launched, the &lt;em&gt;site-packages&lt;/em&gt; of the virtual environment will be available in the &lt;code&gt;PYTHONPATH&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Back to &lt;em&gt;proj3&lt;/em&gt;, after run &lt;code&gt;workon proj3&lt;/code&gt;, it is possible to execute &lt;code&gt;iPython&lt;/code&gt; to be in the interactive mode, or &lt;code&gt;jupyter-notebook&lt;/code&gt; to use the notebook.&lt;/p&gt;
&lt;h2 id=&#34;updating-the-package-with-pip&#34;&gt;Updating the package with pip&lt;/h2&gt;
&lt;p&gt;In order to update the different &lt;strong&gt;Python&lt;/strong&gt; packages, run the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip list --outdated | cut -d &amp;quot; &amp;quot; -f 1 | xargs -n1 pip install -U
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Set up R</title>
      <link>/post/set-up-r/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      <guid>/post/set-up-r/</guid>
      <description>&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://cran.r-project.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/a&gt;
 is very easy to install on MacOS.&lt;/p&gt;
&lt;p&gt;The first thing to do is to add &lt;strong&gt;R&lt;/strong&gt; to the available formulae in &lt;strong&gt;Homebrew&lt;/strong&gt;. And then, install &lt;strong&gt;R&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew tap homebrew/science
brew install r
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It could be necessary to install &lt;strong&gt;XQuartz&lt;/strong&gt; to use &lt;strong&gt;R&lt;/strong&gt; (but it is also possible that it is installed by default)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew cask install xquartz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A nice GUI to use with &lt;strong&gt;R&lt;/strong&gt; is &lt;strong&gt;Rstudio&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew cask install rstudio
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;jupyter-kernel&#34;&gt;Jupyter kernel&lt;/h2&gt;
&lt;p&gt;The installation of the &lt;strong&gt;R&lt;/strong&gt; kernel for Jupyter is straightforward following this 
&lt;a href=&#34;https://irkernel.github.io/installation/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;On MacOS, from a Terminal, run &lt;code&gt;R&lt;/code&gt; to launch a &lt;strong&gt;R&lt;/strong&gt; session. Then, run the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&#39;IRKernel&#39;) # Install the package
IRKernel::installspec() # Make Jupyter to see the R kernel
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;configuration-of-the-proxies&#34;&gt;Configuration of the proxies&lt;/h2&gt;
&lt;p&gt;How to install packages if you have to deal with proxies? First, you should know the repository where &lt;strong&gt;R&lt;/strong&gt; is installed.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;R.home()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then, you have to add to the file &lt;code&gt;${R_HOME}/etc/Renviron&lt;/code&gt; the lines:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;http_proxy=http://&amp;lt;user_name&amp;gt;:&amp;lt;password&amp;gt;@&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/
https_proxy=https://&amp;lt;user_name&amp;gt;:&amp;lt;password&amp;gt;@&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/
ftp_proxy=ftp://&amp;lt;user_name&amp;gt;:&amp;lt;password&amp;gt;@&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;/
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;some-modification-to-functions&#34;&gt;Some modification to functions&lt;/h2&gt;
&lt;h3 id=&#34;summary-functions&#34;&gt;Summary functions&lt;/h3&gt;
&lt;details&gt;
&lt;summary&gt;Dataframe summary&lt;/summary&gt;
&lt;p&gt;
```{r}
summary_df &lt;- function(df){
  # Function that get a dataframe as input and return a list with two entries.
  # One entry is for factor variables, which is a list that count the factors.
  # The other entry is for numeric variables, which contains statistics on it.
  result &lt;- list()
&lt;p&gt;if(any(sapply(df, class) == &amp;lsquo;factor&amp;rsquo;)){
result$Factor &amp;lt;- df %&amp;gt;% select_if(is.factor) %&amp;gt;% imap(summary_column)
}
if(any(sapply(df, class) == &amp;lsquo;numeric&amp;rsquo;)){
result$Numeric &amp;lt;- df %&amp;gt;% select_if(is.numeric) %&amp;gt;% imap_dfr(summary_column)
}&lt;/p&gt;
&lt;p&gt;return(result)
}&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;/p&amp;gt;
&amp;lt;/details&amp;gt;	

&amp;lt;details&amp;gt;
&amp;lt;summary&amp;gt;Column dataframe summary&amp;lt;/summary&amp;gt;
&amp;lt;p&amp;gt;
```{r}
summary_column &amp;lt;- function(df.column, name.column){
  # Function that get a column from a dataframe and return statistics on it.
  # Depending on the column class, the results will not be the same.
  if(class(df.column) == &#39;factor&#39;){
    colName &amp;lt;- name.column
    df.column %&amp;gt;% fct_count() %&amp;gt;% rename(!!colName := f, Count = n)    
  } else if(class(df.column) == &#39;numeric&#39;){
    tibble(
      Name = name.column,
      NA_num = sum(is.na(df.column)),
      Unique = length(unique(df.column)),
      Range = max(df.column, na.rm = TRUE) - min(df.column, na.rm = TRUE),
      Mean = round(mean(df.column, na.rm = TRUE), digits = 2),
      Variance = round(var(df.column, na.rm = TRUE), digits = 2),
      Minimum = min(df.column, na.rm = TRUE),
      Q05 = quantile(df.column, probs = .05, na.rm = TRUE),
      Q10 = quantile(df.column, probs = .10, na.rm = TRUE),
      Q25 = quantile(df.column, probs = .25, na.rm = TRUE),
      Q50 = quantile(df.column, probs = .50, na.rm = TRUE),
      Q75 = quantile(df.column, probs = .75, na.rm = TRUE),
      Q90 = quantile(df.column, probs = .90, na.rm = TRUE),
      Q95 = quantile(df.column, probs = .95, na.rm = TRUE),
      Maximum = max(df.column, na.rm = TRUE)
    )
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;h3 id=&#34;print-functions&#34;&gt;Print functions&lt;/h3&gt;
&lt;details&gt;
&lt;summary&gt;Print summary dataframe&lt;/summary&gt;
&lt;p&gt;
```{r}
print_summary_df &lt;- function(l){
  # Print function for the summary of dataframe to be rendered in html.
  for(i in seq_along(l)){
    cat(glue::glue(&#34;&lt;ul&gt;&#34;))
    cat(glue::glue(&#34;&lt;li&gt; **{names(l)[i]} variables** &lt;/li&gt;\n\n&#34;))
    if(class(l[[i]]) == &#39;list&#39;){
      for(j in seq_along(l[[i]])){
        cat(glue::glue(&#34;&lt;ul&gt;&#34;))
        cat(glue::glue(&#34;&lt;li&gt; {names(l[[i]][j])} &lt;/li&gt;\n\n&#34;))
        cat(&#39;&lt;div style=&#34;overflow-x:auto;&#34;&gt;\n&#39;)
        l[[i]][j] %&gt;%
          kable(format = &#39;html&#39;) %&gt;%
          kable_styling(bootstrap_options = c(&#34;striped&#34;, &#34;hover&#34;, &#34;condensed&#34;, &#34;responsive&#34;), position = &#34;center&#34;) %&gt;%
          print()
        cat(&#39;&lt;/div&gt;&lt;/ul&gt;\n\n&#39;)
      }
    } else{
      cat(&#39;&lt;div style=&#34;overflow-x:auto;&#34;&gt;\n&#39;)
      l[[i]] %&gt;%
        kable(format = &#39;html&#39;) %&gt;%
        kable_styling(bootstrap_options = c(&#34;striped&#34;, &#34;hover&#34;, &#34;condensed&#34;, &#34;responsive&#34;), position = &#34;center&#34;) %&gt;%
        print()  
       cat(&#39;&lt;/div&gt;\n&#39;)
    }
    cat(glue::glue(&#34;&lt;/ul&gt;\n&#34;))
  }
}
&lt;pre&gt;&lt;code&gt;&amp;lt;/p&amp;gt;
&amp;lt;/details&amp;gt;

&amp;lt;details&amp;gt;
&amp;lt;summary&amp;gt;Print dataframe&amp;lt;/summary&amp;gt;
&amp;lt;p&amp;gt;
```{r}
print_df &amp;lt;- function(l){
  # Print function for dataframe to be renderer in html.
  cat(&#39;&amp;lt;div style=&amp;quot;overflow-x:auto;&amp;quot;&amp;gt;\n&#39;)
  l %&amp;gt;% 
    kable(format = &#39;html&#39;) %&amp;gt;%
    kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;), position = &amp;quot;center&amp;quot;) %&amp;gt;%
    print()
  cat(&#39;&amp;lt;/div&amp;gt;&amp;lt;/ul&amp;gt;\n\n&#39;)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;Print summary lm&lt;/summary&gt;
&lt;p&gt;
```{r}
print_summary_lm &lt;- function(lm_summary){
  # Print function for lm summary to be renderer in html.
  cat(glue::glue(&#34;Results of the linear model on the **{lm_summary$call$data}** dataset.\n&#34;))
&lt;p&gt;cat(glue::glue(&amp;ldquo;&lt;ul&gt;&amp;rdquo;))&lt;/p&gt;
&lt;h1 id=&#34;print-the-formula&#34;&gt;Print the formula&lt;/h1&gt;
&lt;p&gt;cat(glue::glue(&amp;ldquo;&lt;li&gt; &lt;em&gt;Formula&lt;/em&gt;: &amp;ldquo;,
&amp;ldquo;{deparse(lm_summary$call$formula)} &lt;/li&gt;&amp;rdquo;))&lt;/p&gt;
&lt;h1 id=&#34;treat-the-residuals&#34;&gt;Treat the residuals&lt;/h1&gt;
&lt;p&gt;cat(glue::glue(&amp;ldquo;&lt;li&gt; &lt;em&gt;Residuals&lt;/em&gt; &lt;/li&gt;\n&amp;rdquo;))
cat(&amp;lsquo;&lt;div style=&#34;overflow-x:auto;&#34;&gt;\n&amp;rsquo;)
lm_summary$residuals %&amp;gt;% summary_column(name.column = &amp;lsquo;Residuals&amp;rsquo;) %&amp;gt;%
kable(format = &amp;lsquo;html&amp;rsquo;, digits = 2) %&amp;gt;%
kable_styling(bootstrap_options = c(&amp;ldquo;striped&amp;rdquo;, &amp;ldquo;hover&amp;rdquo;, &amp;ldquo;condensed&amp;rdquo;, &amp;ldquo;responsive&amp;rdquo;), position = &amp;ldquo;center&amp;rdquo;) %&amp;gt;%
print()
cat(&amp;lsquo;&lt;/div&gt;\n\n&amp;rsquo;)&lt;/p&gt;
&lt;h1 id=&#34;treat-the-regression-coefficient&#34;&gt;Treat the regression coefficient&lt;/h1&gt;
&lt;p&gt;cat(glue::glue(&amp;ldquo;&lt;li&gt; &lt;em&gt;Coefficients&lt;/em&gt; &lt;/li&gt;\n&amp;rdquo;))
cat(&amp;lsquo;&lt;div style=&#34;overflow-x:auto;&#34;&gt;\n&amp;rsquo;)
coef &amp;lt;- lm_summary$coefficients
coef[, &amp;lsquo;Pr(&amp;gt;|t|)&#39;] &amp;lt;- format.pval(coef[, &amp;lsquo;Pr(&amp;gt;|t|)&#39;])
coef &amp;lt;- coef %&amp;gt;% as.data.frame(stringsAsFactors = FALSE) %&amp;gt;%
rownames_to_column(&amp;lsquo;Variable&amp;rsquo;) %&amp;gt;%
as.tibble() %&amp;gt;%
map_at(c(&amp;ldquo;Estimate&amp;rdquo;, &amp;ldquo;Std. Error&amp;rdquo;, &amp;ldquo;t value&amp;rdquo;), as.numeric)
coef %&amp;gt;% as.tibble() %&amp;gt;%
kable(format = &amp;lsquo;html&amp;rsquo;, digits = 5) %&amp;gt;%
kable_styling(bootstrap_options = c(&amp;ldquo;striped&amp;rdquo;, &amp;ldquo;hover&amp;rdquo;, &amp;ldquo;condensed&amp;rdquo;, &amp;ldquo;responsive&amp;rdquo;), position = &amp;ldquo;center&amp;rdquo;) %&amp;gt;%
print()
cat(&amp;lsquo;&lt;/div&gt;\n\n&amp;rsquo;)&lt;/p&gt;
&lt;h1 id=&#34;treat-other-stats&#34;&gt;Treat other stats&lt;/h1&gt;
&lt;p&gt;pval &amp;lt;- format.pval(pf(lm_summary$fstatistic[1L], lm_summary$fstatistic[2L],
lm_summary$fstatistic[3L], lower.tail = FALSE), digits = 3)
cat(glue::glue(&amp;ldquo;&lt;li&gt; &lt;em&gt;Residual standard error&lt;/em&gt;: &amp;ldquo;,
&amp;ldquo;{round(lm_summary$sigma, 3)} on {lm_summary$df[2]} degrees of freedom. &lt;/li&gt;&amp;rdquo;))
cat(glue::glue(&amp;ldquo;&lt;li&gt; &lt;em&gt;Multiple $R^2$&lt;/em&gt;: {round(lm_summary$r.squared, 3)}.&lt;/li&gt;&amp;rdquo;))
cat(glue::glue(&amp;ldquo;&lt;li&gt; &lt;em&gt;Adjusted $R^2$&lt;/em&gt;: {round(lm_summary$adj.r.squared, 3)}.&lt;/li&gt;&amp;rdquo;))
cat(glue::glue(&amp;ldquo;&lt;li&gt; &lt;em&gt;F-statistic&lt;/em&gt;: &amp;ldquo;,
&amp;ldquo;{round(lm_summary$fstatistic[1L], 3)} on {lm_summary$fstatistic[2L]} and {lm_summary$fstatistic[3L]}, &amp;ldquo;,
&amp;ldquo;p-value: {pval}. &lt;/li&gt;&amp;rdquo;))&lt;/p&gt;
&lt;p&gt;cat(glue::glue(&amp;ldquo;&lt;/ul&gt;&amp;rdquo;))
}&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;/p&amp;gt;
&amp;lt;/details&amp;gt;

&amp;lt;details&amp;gt;
&amp;lt;summary&amp;gt;Print summary glm&amp;lt;/summary&amp;gt;
&amp;lt;p&amp;gt;
```{r}
print_summary_glm &amp;lt;- function(glm_summary){
  cat(glue::glue(&amp;quot;Results of the model on the **{glm_summary$call$data}** dataset.\n&amp;quot;))
  
  cat(glue::glue(&amp;quot;&amp;lt;ul&amp;gt;&amp;quot;))
  # Print the formula
  cat(glue::glue(&amp;quot;&amp;lt;li&amp;gt; *Formula*: &amp;quot;, 
                 &amp;quot;{deparse(glm_summary$call$formula)} &amp;lt;/li&amp;gt;&amp;quot;))
  
  # Treat the residuals
  cat(glue::glue(&amp;quot;&amp;lt;li&amp;gt; *Residuals* &amp;lt;/li&amp;gt;\n&amp;quot;))
  cat(&#39;&amp;lt;div style=&amp;quot;overflow-x:auto;&amp;quot;&amp;gt;\n&#39;)
  glm_summary$deviance.resid %&amp;gt;% summary_column(name.column = &#39;Residuals&#39;) %&amp;gt;%
    kable(format = &#39;html&#39;, digits = 2) %&amp;gt;%
    kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;), position = &amp;quot;center&amp;quot;) %&amp;gt;%
    print()
  cat(&#39;&amp;lt;/div&amp;gt;\n\n&#39;)
  
  # Treat the regression coefficient
  cat(glue::glue(&amp;quot;&amp;lt;li&amp;gt; *Coefficients* &amp;lt;/li&amp;gt;\n&amp;quot;))
  cat(&#39;&amp;lt;div style=&amp;quot;overflow-x:auto;&amp;quot;&amp;gt;\n&#39;)
  coef &amp;lt;- glm_summary$coefficients
  coef[, &#39;Pr(&amp;gt;|z|)&#39;] &amp;lt;- format.pval(coef[, &#39;Pr(&amp;gt;|z|)&#39;])
  coef &amp;lt;- coef %&amp;gt;% as.data.frame(stringsAsFactors = FALSE) %&amp;gt;% 
    rownames_to_column(&#39;Variable&#39;) %&amp;gt;% 
    as.tibble() %&amp;gt;% 
    map_at(c(&amp;quot;Estimate&amp;quot;, &amp;quot;Std. Error&amp;quot;, &amp;quot;z value&amp;quot;), as.numeric)
  coef %&amp;gt;% as.tibble() %&amp;gt;%
    kable(format = &#39;html&#39;, digits = 5) %&amp;gt;%
    kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;, &amp;quot;responsive&amp;quot;), position = &amp;quot;center&amp;quot;) %&amp;gt;%
    print()
  cat(&#39;&amp;lt;/div&amp;gt;\n\n&#39;)
  
  # Treat other stats
  cat(glue::glue(&amp;quot;&amp;lt;li&amp;gt; *Null deviance*: &amp;quot;, 
                 &amp;quot;{round(glm_summary$null.deviance, 3)} on {glm_summary$df.null} degrees of freedom. &amp;lt;/li&amp;gt;&amp;quot;))
  cat(glue::glue(&amp;quot;&amp;lt;li&amp;gt; *Residual deviance*: &amp;quot;, 
                 &amp;quot;{round(glm_summary$deviance, 3)} on {glm_summary$df.residual} degrees of freedom. &amp;lt;/li&amp;gt;&amp;quot;))
  cat(glue::glue(&amp;quot;&amp;lt;li&amp;gt; *AIC*: &amp;quot;, 
                 &amp;quot;{round(glm_summary$aic, 3)}&amp;lt;/li&amp;gt;&amp;quot;))
  
  cat(glue::glue(&amp;quot;&amp;lt;/ul&amp;gt;\n&amp;quot;))
}

&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;h3 id=&#34;plot-functions&#34;&gt;Plot functions&lt;/h3&gt;
&lt;details&gt;
&lt;summary&gt;Plot confusion matrix&lt;/summary&gt;
&lt;p&gt;
```{r}
plot_confusion_matrix &lt;- function(confusion_matrix){
  confusion_matrix %&gt;%
    as.data.frame(optional = TRUE) %&gt;% 
    rownames_to_column() %&gt;%
    rename(&#39;Var1&#39; = &#39;.&#39;) %&gt;%
    ggplot() +
    geom_text(aes(x = Var1, y = Var2, label = Freq), size = 4) +
    xlab(&#39;Prediction&#39;) +
    ylab(&#39;True&#39;) +
    geom_hline(aes(yintercept = 1.5), size = 0.2) +
    geom_vline(aes(xintercept = 1.5), size = 0.2) +
    theme_bw() +
    scale_x_discrete(position = &#34;top&#34;) +
    theme(panel.grid = element_blank(),
          axis.ticks = element_blank())
}
```
&lt;/p&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;Plot regsubset summary&lt;/summary&gt;
&lt;p&gt;
```{r}
ggregsubsets &lt;- function(x, criterion = c(&#34;rsq&#34;, &#34;rss&#34;, &#34;adjr2&#34;, &#34;cp&#34;, &#34;bic&#34;)){
  # https://gist.github.com/dkahle/7942a7eba8aaa026d0bab6a1e9d88580
  require(dplyr); require(ggplot2); require(tidyr)
  if(inherits(x, &#34;regsubsets&#34;)) x &lt;- summary(x)
  if(!inherits(x, &#34;summary.regsubsets&#34;))
    stop(&#34;The input to ggregsubsets() should be the result of regsubsets().&#34;)
  df &lt;- bind_cols(
    as.data.frame(x$which), 
    as.data.frame(x[criterion]),
    data.frame(nvars = 1:nrow(x$which))
  )
  names(df)[1] &lt;- &#34;Int&#34;
  if(&#34;rsq&#34; %in% criterion) df &lt;- df %&gt;% mutate(rsq = 100*rsq)
  if(&#34;adjr2&#34; %in% criterion) df &lt;- df %&gt;% mutate(adjr2 = 100*adjr2)
&lt;p&gt;df &amp;lt;- df %&amp;gt;%
gather(variable, is_in, -criterion, -nvars) %&amp;gt;%
gather(measure, value, -nvars, -variable, -is_in)&lt;/p&gt;
&lt;p&gt;if(&amp;ldquo;rsq&amp;rdquo; %in% criterion) df[df[&amp;lsquo;measure&amp;rsquo;] == &amp;lsquo;rsq&amp;rsquo;, &amp;lsquo;measure&amp;rsquo;] &amp;lt;- &amp;lsquo;$R^2$&amp;rsquo;
if(&amp;ldquo;rss&amp;rdquo; %in% criterion) df[df[&amp;lsquo;measure&amp;rsquo;] == &amp;lsquo;rss&amp;rsquo;, &amp;lsquo;measure&amp;rsquo;] &amp;lt;- &amp;lsquo;$RSS$&amp;rsquo;
if(&amp;ldquo;adjr2&amp;rdquo; %in% criterion) df[df[&amp;lsquo;measure&amp;rsquo;] == &amp;lsquo;adjr2&amp;rsquo;, &amp;lsquo;measure&amp;rsquo;] &amp;lt;- &amp;lsquo;Adjusted $R^2$&amp;rsquo;
if(&amp;ldquo;cp&amp;rdquo; %in% criterion) df[df[&amp;lsquo;measure&amp;rsquo;] == &amp;lsquo;cp&amp;rsquo;, &amp;lsquo;measure&amp;rsquo;] &amp;lt;- &amp;lsquo;$C_p$&amp;rsquo;
if(&amp;ldquo;bic&amp;rdquo; %in% criterion) df[df[&amp;lsquo;measure&amp;rsquo;] == &amp;lsquo;bic&amp;rsquo;, &amp;lsquo;measure&amp;rsquo;] &amp;lt;- &amp;lsquo;$BIC$&amp;rsquo;&lt;/p&gt;
&lt;p&gt;p &amp;lt;- ggplot(df, aes(variable, factor(round(value)))) +
geom_tile(aes(fill = is_in)) +
facet_wrap(~ measure, scales = &amp;ldquo;free&amp;rdquo;) +
scale_fill_manual(&amp;quot;&amp;quot;, values = c(&amp;ldquo;TRUE&amp;rdquo; = &amp;ldquo;black&amp;rdquo;, &amp;ldquo;FALSE&amp;rdquo; = &amp;ldquo;white&amp;rdquo;), guide = FALSE) +
labs(x = &amp;ldquo;&amp;quot;, y = &amp;ldquo;&amp;quot;)
return(p)
}&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;/p&amp;gt;
&amp;lt;/details&amp;gt;

&amp;lt;details&amp;gt;
&amp;lt;summary&amp;gt;Plot criteria for model selection&amp;lt;/summary&amp;gt;
&amp;lt;p&amp;gt;
```{r}
ggcriteria &amp;lt;- function(x, criterion = &amp;quot;bic&amp;quot;){
  require(dplyr); require(ggplot2); require(tidyr)
  if(inherits(x, &amp;quot;regsubsets&amp;quot;)) x &amp;lt;- summary(x)
  if(!inherits(x, &amp;quot;summary.regsubsets&amp;quot;))
    stop(&amp;quot;The input to ggregsubsets() should be the result of regsubsets().&amp;quot;)
  
  if(&amp;quot;rsq&amp;quot; == criterion) crit &amp;lt;- &#39;$R^2$&#39;
  if(&amp;quot;rss&amp;quot; == criterion) crit &amp;lt;- &#39;$RSS$&#39;
  if(&amp;quot;adjr2&amp;quot; == criterion) crit &amp;lt;- &#39;Adjusted $R^2$&#39;
  if(&amp;quot;cp&amp;quot; == criterion) crit &amp;lt;- &#39;$C_p$&#39;
  if(&amp;quot;bic&amp;quot; == criterion) crit &amp;lt;- &#39;$BIC$&#39;
  
  if((criterion == &amp;quot;adjr2&amp;quot;) | (criterion == &amp;quot;rsq&amp;quot;)) m &amp;lt;- which.max(x[[criterion]])
  else m &amp;lt;- which.min(x[[criterion]])
  
  p &amp;lt;- ggplot() +
    geom_line(aes(x = seq(1, length(x[[criterion]])), y = x[[criterion]])) + 
    geom_point(aes(x = m, y = x[[criterion]][m]), col = &#39;red&#39;, size = 3) +
    xlab(&#39;Number of variables&#39;) +
    scale_x_continuous(breaks = seq(1, length(x[[criterion]])), minor_breaks = NULL) +
    ylab(crit)
  return(p)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;Plot cross-validation error from `cv.glmnet` function&lt;/summary&gt;
&lt;p&gt;
```{r}
ggcv.glmnet &lt;- function(x){
  require(dplyr); require(ggplot2); require(glmnet)
  if(!inherits(x, &#34;cv.glmnet&#34;))
    stop(&#34;The input of ggcv.glmnet() should be the result og cv.glmnet().&#34;)
&lt;p&gt;df &amp;lt;- tibble(lambda = log(x$lambda), cvm = x$cvm, cvsd = x$cvsd)
p &amp;lt;- ggplot(df, aes(lambda, cvm, ymin = cvm - cvsd, ymax = cvm + cvsd)) +
geom_point(col = &amp;lsquo;red&amp;rsquo;) +
geom_errorbar() +
geom_vline(aes(xintercept = df$lambda[which.min(df$cvm)]), col = &amp;lsquo;blue&amp;rsquo;, linetype = 2) +
xlab(&amp;lsquo;$\log(\lambda)$&amp;rsquo;) +
ylab(&amp;lsquo;Mean-Squared Error&amp;rsquo;)
return(p)
}&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;/p&amp;gt;
&amp;lt;/details&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Titanic: Machine Learning from Disaster</title>
      <link>/project/titanic/</link>
      <pubDate>Thu, 22 Nov 2018 00:00:00 +0000</pubDate>
      <guid>/project/titanic/</guid>
      <description>&lt;h2 id=&#34;context&#34;&gt;Context&lt;/h2&gt;
&lt;p&gt;The sinking of the RMS Titanic is one of the most infamous shipwrecks in
history. On April 15, 1912, during her maiden voyage, the Titanic sank
after colliding with an iceberg, killing 1502 out of 2224 passengers and
crew. This sensational tragedy shocked the international community and
led to better safety regulations for ships.&lt;/p&gt;
&lt;p&gt;One of the reasons that the shipwreck led to such loss of life was that
there were not enough lifeboats for the passengers and crew. Although
there was some element of luck involved in surviving the sinking, some
groups of people were more likely to survive than others, such as women,
children, and the upper-class.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;variables-description&#34;&gt;Variables description&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Variable Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;PassengerId&lt;/td&gt;
&lt;td&gt;Passengerâs Id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Survived&lt;/td&gt;
&lt;td&gt;Survived (1) or died (0)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pclass&lt;/td&gt;
&lt;td&gt;Passengerâs class&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Name&lt;/td&gt;
&lt;td&gt;Passengerâs name&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sex&lt;/td&gt;
&lt;td&gt;Passengerâs sex&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Age&lt;/td&gt;
&lt;td&gt;Passengerâs age&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SibSp&lt;/td&gt;
&lt;td&gt;Number of siblings/spouses aboard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Parch&lt;/td&gt;
&lt;td&gt;Number of parents/children aboard&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ticket&lt;/td&gt;
&lt;td&gt;Ticket number&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Fare&lt;/td&gt;
&lt;td&gt;Passenger Fare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Cabin&lt;/td&gt;
&lt;td&gt;Cabin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Embarked&lt;/td&gt;
&lt;td&gt;Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;SPECIAL NOTES&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Pclass&lt;/em&gt; is a proxy for socio-economic status (SES): 1st ~ Upper; 2nd
~ Middle; 3rd ~ Lower.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Age&lt;/em&gt; is in Years; fractional if &lt;em&gt;Age&lt;/em&gt; is less than One (1). If the
&lt;em&gt;Age&lt;/em&gt; is estimated, it is in the form xx.5.&lt;/p&gt;
&lt;p&gt;With respect to the family relation variables (i.e. &lt;em&gt;sibsp&lt;/em&gt; and &lt;em&gt;parch&lt;/em&gt;)
some relations were ignored. The following are the definitions used for
&lt;em&gt;sibsp&lt;/em&gt; and &lt;em&gt;parch&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sibling: Brother, Sister, Stepbrother, or Stepsister of Passenger
Aboard Titanic;&lt;/li&gt;
&lt;li&gt;Spouse: Husband or Wife of Passenger Aboard Titanic (Mistresses and
Fiances Ignored);&lt;/li&gt;
&lt;li&gt;Parent: Mother or Father of Passenger Aboard Titanic;&lt;/li&gt;
&lt;li&gt;Child: Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard
Titanic.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other family relatives excluded from this study include cousins,
nephews/nieces, aunts/uncles, and in-laws. Some children travelled only
with a nanny, therefore &lt;em&gt;parch&lt;/em&gt; = 0 for them. As well, some travelled
with very close friends or neighbors in a village, however, the
definitions do not support such relations.&lt;/p&gt;
&lt;h2 id=&#34;load-the-data&#34;&gt;Load the data&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train &amp;lt;- read_csv(&#39;train.csv&#39;)
test &amp;lt;- read_csv(&#39;test.csv&#39;)

titanic &amp;lt;- train %&amp;gt;% 
            bind_rows(test) %&amp;gt;%
            select(-PassengerId) %&amp;gt;%
            mutate_at(vars(Pclass, Sex, Embarked), funs(factor(.)))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The train dataset has 891 observations and 12 variables. The test
dataset has 418 observations and 11 variables. We want to use the
&lt;code&gt;train&lt;/code&gt; dataset to learn if a passenger survived given the different
variables, and then predict the fate of the passenger into the &lt;code&gt;test&lt;/code&gt;
dataset.&lt;/p&gt;
&lt;h2 id=&#34;exploratory-data-analysis&#34;&gt;Exploratory Data Analysis&lt;/h2&gt;
&lt;h3 id=&#34;passengers-class&#34;&gt;Passengerâs class&lt;/h3&gt;
&lt;p&gt;There is no missing values into the &lt;em&gt;PClass&lt;/em&gt; variable. Half of the
passenger are in the third class.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;class-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;passengers-sex&#34;&gt;Passengerâs sex&lt;/h3&gt;
&lt;p&gt;There is almost twice men than women.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;sex-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;passengers-name&#34;&gt;Passengerâs name&lt;/h3&gt;
&lt;p&gt;This variable, obviously, confirm the high number of men compare to the
number of women. But it carry another piece of information: more than
the half of the women on the Titanic are not married (the &lt;code&gt;Miss&lt;/code&gt;
factor). It is probably due to the children.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Extract the title from the Passenger&#39;s name.
Title &amp;lt;- &amp;quot;^.*, (.*?)\\..*$&amp;quot; %&amp;gt;% 
          gsub(&amp;quot;\\1&amp;quot;, titanic$Name)
# Create another factors for low represented title.
title_high &amp;lt;- c(&#39;Mr&#39;, &#39;Miss&#39;, &#39;Mrs&#39;, &#39;Master&#39;)
Title &amp;lt;- Title %in% title_high %&amp;gt;%
          if_else(Title, &#39;Other&#39;)
# Add titlecolumn to the dataframe
titanic &amp;lt;- titanic %&amp;gt;% 
            add_column(Title) %&amp;gt;%
            mutate_at(vars(Title), funs(factor(.)))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;name-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;passengers-port-of-embarkation&#34;&gt;Passengerâs port of embarkation&lt;/h3&gt;
&lt;p&gt;1 % of the passengers embarked in Southampton. We do not known the port
of embarkation for only 2 persons. So, we will try to infer these
missing values.&lt;/p&gt;
&lt;p&gt;First, letâs take a look at the 2 passengers with missing port of
embarkation.&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Survived
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Pclass
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Name
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Sex
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Age
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
SibSp
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Parch
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Ticket
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Fare
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Cabin
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Embarked
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Title
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Icard, Miss. Amelie
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
113572
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
80
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B28
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Miss
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Stone, Mrs. George Nelson (Martha Evelyn)
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
female
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
62
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
113572
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
80
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
B28
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mrs
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Miss. Icard and Mrs. Stone paid 80$ and was in first class. Letâs plot a
boxplot to determine the median fare depending on the port of
embarkation for the first class.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;plot_missing_embarked-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;There are only 3 passengers that embarked in Queenstown in first class.
There fare was 90$. Moreover, they were part of the same family. So,
considering the boxplot, we might think that the port of embarkation of
Miss. Icard and Mrs. Stone were Cherbourg.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;titanic[62, &amp;quot;Embarked&amp;quot;] &amp;lt;- &amp;quot;C&amp;quot;
titanic[830, &amp;quot;Embarked&amp;quot;] &amp;lt;- &amp;quot;C&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;port-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;passengers-fare&#34;&gt;Passengerâs fare&lt;/h3&gt;
&lt;p&gt;There is only 1 person with a missing in the all dataset. The mean fare
is 33$ and the median fare 14$ for a ticket on the Titanic. Letâs look
at the person with a missing fare.&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Survived
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Pclass
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Name
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Sex
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Age
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
SibSp
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Parch
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Ticket
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Fare
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Cabin
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Embarked
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Title
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Storey, Mr. Thomas
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
male
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
60.5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3701
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
S
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Mr
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Letâs plot a kernel density estimator of the fare for the person with
the same characteristics than Mr. Storey (embarked in Southampton in
third class).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;plot_fare-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The median for the third class and the embarkment in Southampton is 8$.
So, we might think that Mr. Storey has paid the median fare of the
people from the third class who embarked in Southampton.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;titanic[1044, &amp;quot;Fare&amp;quot;] &amp;lt;- titanic %&amp;gt;% filter(Embarked == &#39;S&#39;, Pclass == 3) %&amp;gt;% pull(Fare) %&amp;gt;% median(na.rm = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;passengers-age&#34;&gt;Passengerâs age&lt;/h3&gt;
&lt;p&gt;There are 263 persons without &lt;em&gt;Age&lt;/em&gt; in the dataset. The mean age is 29.9
years old.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;plot_age-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Since there are a lot of missing values, we are going to input these
ones using a ridge regression (
&lt;a href=&#34;https://cran.r-project.org/web/packages/glmnet/glmnet.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;glmnet_
package&lt;/a&gt;
).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Split the dataset into the ones with Age and the ones without Age.
titanic.with.age &amp;lt;- titanic %&amp;gt;% 
  filter(!is.na(Age)) %&amp;gt;%
  select(-c(Survived, Name, Ticket, Cabin))
titanic.without.age &amp;lt;- titanic %&amp;gt;%
  filter(is.na(Age)) %&amp;gt;%
  select(-c(Survived, Name, Ticket, Cabin)) %&amp;gt;%
  mutate(Age = 0)

# Build a model matrix of the data
titanic.lm &amp;lt;- lm(Age ~ ., data = titanic.with.age)
titanic.with.age.model.matrix &amp;lt;- model.matrix(titanic.lm, data = titanic.with.age)[,-1]
# Perform the Ridge Regression (alpha = 0)
titanic.age.model &amp;lt;- glmnet(titanic.with.age.model.matrix, titanic.with.age$Age, alpha = 0)

# Prediction of the Age 
titanic.without.age$Age &amp;lt;- predict(titanic.age.model, 
  newx = model.matrix(titanic.lm, data = titanic.without.age)[, -1],
  s = cv.glmnet(titanic.with.age.model.matrix, titanic.with.age$Age, alpha = 0)$lambda.min,
  type = &#39;link&#39;)

# Replace the missing Age into the all dataset
titanic[is.na(titanic$Age), &amp;quot;Age&amp;quot;] &amp;lt;- titanic.without.age$Age
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Letâs check the new density estimator for the &lt;em&gt;Age&lt;/em&gt; to ensure that
things still look good. (Careful, one person with a predicted negative
age!)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;plot_age2-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;number-of-siblingsspouses-aboard&#34;&gt;Number of siblings/spouses aboard&lt;/h3&gt;
&lt;p&gt;There is no missing value for the variable &lt;em&gt;SipSp&lt;/em&gt; in the dataset. A
majority if the passengers does not have siblings or spouses aboard.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;plot_sipsp-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;number-of-parentschildren-aboard&#34;&gt;Number of parents/children aboard&lt;/h3&gt;
&lt;p&gt;There is no missing value for the variable &lt;em&gt;Parch&lt;/em&gt; in the dataset. A
majority if the passengers does not have parents or children aboard.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;plot_parch-1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;passengers-cabin&#34;&gt;Passengerâs cabin&lt;/h3&gt;
&lt;p&gt;There are 1014 missing values for the &lt;em&gt;Cabin&lt;/em&gt; variable. So, 77% of the
observations are missing. We decided to delete this features from the
dataset.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;titanic &amp;lt;- titanic %&amp;gt;% select(-Cabin)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;passengers-ticket&#34;&gt;Passengerâs ticket&lt;/h3&gt;
&lt;p&gt;There are 0 missing values for the &lt;em&gt;Ticket&lt;/em&gt; variable. But, there are 929
different values. Thus, we also delete this feature from the dataset
because almost every passenger has a different Ticket.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;titanic &amp;lt;- titanic %&amp;gt;% select(-Ticket)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;prediction-of-the-survivors&#34;&gt;Prediction of the survivors&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;train &amp;lt;- titanic %&amp;gt;% select(-Name) %&amp;gt;% filter(!is.na(Survived))
test &amp;lt;- titanic %&amp;gt;% select(-Name) %&amp;gt;% filter(is.na(Survived))

# Split the train set into two dataset (for validation)
set.seed(42)
sample &amp;lt;- sample(c(TRUE, FALSE), nrow(train), replace = TRUE, prob = c(2/3, 1/3))
train.val &amp;lt;- train[sample, ]
test.val &amp;lt;- train[!sample, ]

# Perform Ridge regression
train.lm &amp;lt;- lm(Survived ~ ., data = train.val)
X &amp;lt;- model.matrix(train.lm, data = train.val)[ , -1]
Y &amp;lt;- train.val$Survived
train.ridge.model &amp;lt;- glmnet(X, Y, alpha = 0, family = &#39;binomial&#39;)

# Prediction on the test.val set
test.val.predict &amp;lt;- predict(train.ridge.model, 
                            s = cv.glmnet(X, Y, alpha = 0)$lambda.min,
                            newx = model.matrix(train.lm, data = test.val)[ , -1],
                            type = &#39;class&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On the validation set, there are 0.14% of missclassified passengers.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Prediction of the test set
test$Survived &amp;lt;- 0
test.predict &amp;lt;- predict(train.ridge.model, 
                        s = cv.glmnet(X, Y, alpha = 0)$lambda.min,
                        newx = model.matrix(train.lm, data = test)[ , -1],
                        type = &#39;class&#39;) 

# Construt the dataframe
result &amp;lt;- data.frame(PassengerID = row.names(test.predict),
                     Survived = test.predict[ , 1])

# Export as CSV
write.csv(result, &#39;results.csv&#39;, row.names = FALSE)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/privacy/</guid>
      <description>&lt;p&gt;Add your privacy policy here and set &lt;code&gt;draft: false&lt;/code&gt; to publish it. Otherwise, delete this file if you don&amp;rsquo;t need it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/terms/</guid>
      <description>&lt;p&gt;Add your terms here and set &lt;code&gt;draft: false&lt;/code&gt; to publish it. Otherwise, delete this file if you don&amp;rsquo;t need it.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
